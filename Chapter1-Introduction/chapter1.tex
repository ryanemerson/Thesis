\chapter{Introduction}
    % **************************** Define Graphics Path **************************
    \graphicspath{{Chapter1-Introduction/Figs/Vector/}{Chapter1-Introduction/Figs/}}
    
    The emergence and proliferation of mainstream cloud computing has facilitated the creation of a large number of Internet-scale web services and applications.  Such services serve millions of users across the globe simultaneously and are required to cater for increasingly large numbers of read and write operations on data with response times in the range of milliseconds. Cloud computing is ideal for such data loads, as it enables the web service to scale horizontally by dynamically acquiring resources as the rate or size of requests increases.  
    
    Traditionally, applications would utilise a Relational Database Management System (RDBMS) for storing and retrieving data.  However, as Internet scale services such as Facebook, Twitter and Google continued to receive increasing numbers of user requests, it became clear that RDBMS systems were unable to cope with such huge quantities of data \citep{DBLP:journals/corr/MoniruzzamanH13}.  The traditional approach to scaling RDBMS, was to scale \emph{vertically}, by utilising increasingly powerful and expensive servers to handle user requests.  Such an approach is not truly scalable as the maximum levels of performance will always be limited by the capabilities of the latest technology, the cost of hardware and the associated running costs.  Alternatively, it is possible to horizontally scale RDBMS solutions by partitioning data across several nodes in order to increase the number of machines that can handle user requests.  However, as RDBMS systems depend on a rigid data-schema to structure data horizontal partitioning is difficult in practice and often requires input from system administrators to maximise its effectiveness \citep{Han:6106531}.          
    
    The emergence of cloud computing as a cost effective model, combined with RDBMS's inability to elastically scale, has led to the emergence of NoSQL databases as an alternative storage solution.  These databases typically offer simpler data models and more relaxed consistency criteria than traditional RDBMS systems, in order to: $(i)$ avoid the need for predefined data schemas that hinder elasticity and $(ii)$ reduce the overhead of maintaining data replicas across multiple nodes \citep{Cattell:2011:SSN:1978915.1978919}.  Consequently, NoSQL stores are highly elastic and very well suited to cloud environments.  
    
    NoSQL databases can effectively utilise horizontal scaling in order to service an increasing number of application requests, whilst also providing increased fault-tolerance, via data replicas that are distributed throughout the cluster.  Utilising multiple data replicas allows for increased levels of throughput as application read requests can be serviced by multiple nodes simultaneously.  However, a consequence of utilising distributed replicas is that each write operation requires several Remote Procedure Calls (RPC) in order to maintain a consistent state between all of the data replicas; with consensus being required between data replicas for each write operation, as all replica hosts must perform write operations  on a given value in the same order.  The cost of obtaining consensus between replicas, coupled with the additional latency cost associated with RPCs, is the primary motivation for NoSQL databases providing weaker consistency guarantees than the traditional 1-copy serialisability provided by ACID transactions in RDBMS.  
    
    Infinispan \citep{Infinispan} is an open source NoSQL database developed by Red Hat, Inc \citep{RedHat} that utilises the RAM of its host machines to store data, which is exposed to applications using a key/value pair model.  When Infinispan is horizontally scaled over multiple nodes it provides two options for distributing key/value pairs: \emph{full} and \emph{partial} replication.  Full replication stores a replica of every key/value on each Infinispan node in the cluster, and consequently is not scalable beyond a small number of nodes.  Conversely, partial replication only stores each key/value pair on a small subset of nodes contained in the cluster and as a result is very scalable when the specified \emph{replication factor} is small; where the \emph{replication factor} is the number of distinct nodes at which each key/value pair is replicated \citep{Schiper:2010:PGP:1915085.1916444}.  
    
    Unlike many NoSQL databases, Infinispan provides support for ACID transactions, however it utilises reduced levels of \emph{isolaton} compared with the traditional 1-copy serialisability in order to improve performance and scalability.  Infinispan's Distributed transactions are coordinated between nodes in a \emph{peer-to-peer} (P2P) manner, using either the classical 2-Phase commit protocol or a lock free total order commit protocol that relies on an atomic multicast protocol.  Existing research \citep{Ruivo:2011:ETO:2120967.2121604} shows that utilising the latter improves performance compared to the 2-Phase commit protocol with respect to transaction abort rates, latency and throughput.  This increase in performance is due to the latter's reliance on a total order of messages, opposed to lock acquisition, to ensure that all data replicas perform write operations in the same order as it is not possible for distributed deadlocks to occur when no locks are used.  
    
    The total order commit protocol provided by Infinispan consistently outperforms 2-Phase commit, however our performance evaluation ($\S$ \ref{ch:perf_eval}) shows that the performance of the underlying atomic multicast protocol currently used for coordinating these transactions does not scale as the number of nodes involved in a transaction becomes greater than three; with the average transaction latency and throughput, increasing and decreasing respectively.  This is acceptable when the specified replication factor is low, for example $2$, as a transaction involving a single write operation will only involve $2$ nodes, however if the replication factor is greater than 2, then performance begins to deteriorate.  This problem is exasperated when a transaction consists of multiple write operations.  For example, if a transaction consists of  $3$ write operations that are performed on distinct keys, and each key/value is replicated twice, then the total number of nodes involved in the transaction can be anywhere between $2$ and $6$ depending on how the keys are distributed across the Infinispan cluster.  Therefore, Infinispan's performance deteriorates if an application requires key/values to be replicated more than twice or an application's workload consists of many transactions involving multiple write operations.  
    
    The scalability problem stated above is not unique to Infinispan's atomic multicast protocol, rather the same limitations apply to any distributed system that utilises P2P protocols to coordinate transactions containing partially replicated data.  Therefore, we define our problem statement for this thesis as designing alternative protocols for obtaining consensus between a subset of cluster nodes, in order to provide improved throughput and latency when coordinating transactions in partially replicated environments.  
    
    \section{Our Approach}    
    In this thesis we advocate an alternative approach to coordinating distributed transactions, which unlike P2P protocols does not require consensus to be reached between peers.  Our approach consists of two key components: an external ordering service that enables atomic multicasts between Infinispan nodes and a non-blocking atomic broadcast protocol for state machine replication within the ordering service.  
   
   The external ordering service is an alternative to the P2P approach currently utilised by Infinispan.  This service consists of a dedicated set of nodes acting as a replicated state machine which provides a total order value for any multicasts required by Infinispan nodes.  The rational behind this approach is that the number of nodes required to reach a consensus on a message's total order is limited to the number of nodes in the ordering service.  Therefore, as the number of nodes participating in a transaction increases, the time required to reach a consensus remains constant, hence the problems associated with P2P protocols in partially replicated environments are circumvented.

    Prior to this research, the throughput capabilities of such a service were limited by the protocols available for replicating state between the nodes providing the ordering service.  Existing coordination services, such as Zookeeper \citep{Hunt:2010:ZWC:1855840.1855851} and Chubby \citep{Burrows:2006:CLS:1298455.1298487}, utilise Quorum based protocols for state machine replication.  Such protocols are advantageous as they do not block in the event of node crashes, however they are dependent on a 'leader' node for coordinating replication which becomes a performance bottleneck as the number of required replications increases.  Such protocols are not suitable for our ordering service, as the service requires a node's state to be replicated each time an ordering request is received and requests are expected to occur frequently.  
    
    An alternative approach to the Quorum based protocols, are group membership dependent atomic broadcast protocols.  Such protocols do not utilise a leader node and provide the best possible throughput and latency when no node crashes occur.  However, when node crashes do occur, message delivery to the application is blocked indefinitely until the group membership service informs the participating nodes that a failure has occurred.  This blocking makes these protocols unsuitable for use within an ordering service as a single service node crash will prevent the ordering service from providing total orders for Infinispan's multicast messages, which in turn prevents any transaction in the Infinispan cluster progressing.  

    Motivated by the limitations of these existing protocols, the second aspect of our research is the development of a hybrid atomic broadcast protocol that can be utilised for fault-tolerant state machine replication.  This protocol combines a deterministic atomic broadcast protocol with a probabilistic one, in order to provide low-latency message delivery in the absence of node failures and non-blocking message delivery in their presence; with the probabilistic protocol guaranteeing atomicity with a probability close to 1.     
   
   Throughout this thesis we have utilised Infinispan as a basis for designing and implementing our solutions.  Infinispan was utilised because it is entirely open source and, at the time of writing, was the only in-memory NoSQL databases that provided support for coordinating ACID transactions via atomic multicasts.  Furthermore, this research was funded in its entirety by Red Hat, Inc who are responsible for the development of Infinispan.  
   
    \section{Thesis Contribution}
    The research presented in this thesis makes several key contributions:
    
	    \begin{enumerate}[label=\roman*]
	        \item An extensive background section that provides the prerequisite information required in order to understand the problem domain.  Of particular significance is the detailed breakdown of the Infinispan NoSQL database and how it addresses the challenges of coordinating distributed transactions in partially replicated environments.  
	        
	        \item A new system model, \textsf{AmaaS}, for coordinating distributed transactions in partially replicated environments and a new fault-tolerant atomic multicast protocol that has been designed specifically for \textsf{AmaaS}.  
	        
	        \item A hybrid atomic broadcast protocol, \textsf{ABcast}, which is designed for providing state machine replication within the \textsf{AmaaS} model.  \textsf{ABcast} provides low-latency message delivery in the absence of node failures and non-blocking message delivery in their presence, by utilising both a deterministic and probabilistic atomic broadcast protocol to deliver messages up the network stack.  
	        
	        \item An extensive performance evaluation of both the \textsf{AmaaS} model and the \textsf{ABcast} protocol.
	    \end{enumerate}
    
    \section{Thesis Structure}
         \begin{description}
             \item[Chapter 1 - Introduction] \hfill \\
             Describes the motivation behind the research presented throughout this document in the form of a problem statement and provides a brief overview of our approach to solving the stated problem.  This is followed by a summary of the key contributions provided by our research.  
             
             \item[Chapter 2 - Background] \hfill \\
             Presents the key prerequisite information required to understand the problem domain.  
             
             \item[Chapter 3 - AmaaS] \hfill \\
             Introduces a new system model for coordinating partially replicated transactions, that we call Atomic Multicast as a Service - \textsf{AmaaS}.  This new model is inherently different from the P2P approach previously utilised by the Infinispan database, therefore we formalise a new fault-tolerant atomic multicast protocol, \textsf{SCast}, for coordinating transactions that utilises \textsf{AmaaS}.  
             
             \item[Chapter 4 - ABcast] \hfill \\
              Presents the rational, design assumptions and important implementation details for the hybrid atomic broadcast protocol \textsf{ABcast}. Followed by an in-depth analysis of the additional application logic required in the \textsf{AmaaS} model when utilising an atomic broadcast protocol that only provides probabilistic guarantees on a message's atomicity.  
             
             \item[Chapter 5 - ABcast Flow Control] \hfill \\
             Details \textsf{AFC}, a bespoke flow-control protocol designed for \textsf{ABcast}.  \textsf{AFC} utilises a rate based approach, coupled with configurable user parameters, to prevent participating nodes from becoming overwhelmed by atomic broadcasts.  
             
             \item[Chapter 6 - Performance Evaluation] \hfill \\
             Provides a thorough performance evaluation of the \textsf{AmaaS} model compared to the existing P2P approach, as well as investigating the effect of utilising different atomic broadcast protocols within the \textsf{AmaaS} service.  Furthermore, we evaluate the performance of the \textsf{ABcast} protocol when node failures occur, in order to ascertain the effectiveness of the protocols non-blocking message delivery.  
             
             \item[Chapter 7 - Conclusions] \hfill \\
             Presents a summary of the findings presented throughout this document and speculates on potential future research made possible by our findings.  
         \end{description}