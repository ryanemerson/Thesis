\chapter{Introduction}
    % **************************** Define Graphics Path **************************
    \graphicspath{{Chapter1-Introduction/Figs/Vector/}{Chapter1-Introduction/Figs/}}
    
    The emergence and proliferation of mainstream cloud computing has facilitated the creation of a large number of Internet-scale web services and applications.  Such services serve millions of users across the globe simultaneously and are required to cater for increasingly large numbers of read and write operations on data.  Furthermore, these data operations need to occur in the range of milliseconds in order to provide the low-latency experience expected by the user's of these services.  Cloud computing is ideal for such workloads, as it enables the web service to scale horizontally by dynamically acquiring resources as the rate or size of requests increases.  
    
    Traditionally, applications would utilise a Relational Database Management System (RDBMS) for storing and retrieving data.  However, as Internet scale services such as Facebook, Twitter and Google continued to receive increasing numbers of user requests, it became clear that RDBMS systems were unable to provide the low-latency responses required by these services when operating at such scale \citep{DBLP:journals/corr/MoniruzzamanH13}.  Therefore it became necessary to seek alternatives to RDBMS which can maintain small response times when operating under such conditions.  
    
    The traditional approach to scaling RDBMS, was to scale \emph{vertically}, by utilising increasingly powerful and expensive servers to handle application requests.  Such an approach is not truly scalable as the maximum levels of performance will always be limited by the capabilities of the latest technology, the cost of hardware and the associated running costs.  Alternatively, it is possible to \emph{horizontally} scale RDBMS solutions by partitioning data across several nodes in order to increase the number of machines that can handle requests.  However, as RDBMS systems depend on a rigid data-schema to structure data, horizontal partitioning is difficult in practice and often requires input from system administrators to maximise its effectiveness \citep{Han:6106531}.  
    
    The emergence of cloud computing as a cost effective model, combined with RDBMS's inability to scale elastically, has led to the emergence of NoSQL databases as an alternative storage solution.  These databases typically offer simpler data models and more relaxed consistency criteria than traditional RDBMS systems, in order to: $(i)$ avoid the need for predefined data schemas that hinder elasticity and $(ii)$ reduce the overhead of maintaining data replicas across multiple nodes \citep{Cattell:2011:SSN:1978915.1978919}.  Consequently, NoSQL stores are highly elastic and are also suited to improving availability through replication, as we explain below.  
    
    NoSQL databases can effectively utilise horizontal scaling in order to service an increasing number of application requests, whilst also providing increased fault-tolerance, via data replicas that are distributed throughout the cluster.  Utilising multiple data replicas allows for increased levels of throughput as application read requests can be serviced by multiple nodes simultaneously.  However, a consequence of utilising distributed replicas is that each write operation requires several Remote Procedure Calls (RPC) in order to maintain a consistent state between all of the data replicas; with consensus being required between data replicas for each write operation, as all replica hosts must perform write operations  on a given value in the same order.  The cost of obtaining consensus between replicas, coupled with the additional latency cost associated with RPCs, is the primary reason for many NoSQL databases choosing to provide weaker consistency guarantees than the traditional 1-copy serialisability provided by ACID transactions in RDBMS.  
    
    Infinispan \citep{Infinispan, marchioni2012infinispan} is an open source NoSQL database developed by Red Hat, Inc \citep{RedHat} that utilises the RAM of its host machines to store data, which is exposed to applications using a key/value model.  When Infinispan is horizontally scaled over multiple nodes it provides two options for distributing key/value pairs: \emph{full} and \emph{partial} replication.  Full replication stores a replica of every key/value on each Infinispan node in the cluster, and consequently is not scalable beyond a small number of nodes.  Conversely, partial replication only stores each key/value pair on a small subset of nodes contained in the cluster and as a result is very scalable when the specified \emph{replication factor} is small; where the \emph{replication factor} is the number of distinct nodes at which each key/value pair is replicated \citep{Schiper:2010:PGP:1915085.1916444}.  
    
    Unlike many NoSQL databases, Infinispan provides support for ACID transactions, however it utilises reduced levels of \emph{isolation} compared with the traditional 1-copy serialisability in order to improve performance and scalability.  Infinispan's distributed transactions are coordinated between nodes in a \emph{peer-to-peer} (P2P) manner, using either the classical 2-Phase commit protocol or a lock free total order commit protocol that relies on an atomic multicast protocol.  Existing research \citep{Ruivo:2011:ETO:2120967.2121604} shows that utilising the latter improves performance compared to the 2-Phase commit protocol with respect to transaction abort rates, latency and throughput.  This increase in performance is due to the latter's reliance on a total order of messages, as opposed to lock acquisition, which ensures that all data replicas perform write operations in the same order, thereby avoiding deadlocks as no locks are used.  
    
    The total order commit protocol provided by Infinispan consistently outperforms 2-Phase commit.  However, our performance evaluation ($\S$ \ref{ch:perf_eval}) shows that the performance of the underlying atomic multicast protocol currently used for coordinating these transactions does not scale as the number of nodes involved in a transaction becomes greater than $3$; with the average transaction latency and throughput, increasing and decreasing respectively.  The atomic multicast protocol's inability to scale is acceptable when both the replication factor and the number of write operations in a transaction is low, however when the replication factor is greater than $2$ or the number of write operations in a transaction is greater than $1$, performance will deteriorate.  For example, if a transaction consists of $3$ write operations that are to be performed on distinct key/value pairs, and Infinisipan utilises the default replication factor of $2$, then the total number of nodes involved in that transaction can be anywhere between $2$ and $6$ nodes depending on how the keys are distributed across the Infinispan cluster.  Hence, it is probable that the total number of destination nodes involved in the atomic multicast that is required to coordinate the transaction will be greater than $3$ and therefore transaction performance will be poor.  
    
    The scalability problem stated above is not unique to Infinispan's atomic multicast protocol, rather the same limitations apply to any distributed system that utilises P2P protocols to coordinate transactions containing partially replicated data.  With these observations in mind, the problem statement for this thesis is formulated below.
    
    \section{Problem Statement}
    To design alternative protocols for totally ordered multicasts between subsets of cluster nodes, in order to improve throughput and latency when coordinating transactions in partially replicated environments.  
    
    \section{Our Approach}    
    In this thesis we advocate an alternative approach to coordinating distributed transactions, which unlike P2P protocols does not require ordering consensus to be reached between peers.  Our approach consists of building two key components: 

	\begin{enumerate}[label=\roman*]
		\item An external ordering service that enables atomic multicasts between Infinispan nodes.
		
		\item A non-blocking atomic broadcast protocol for state machine replication within the ordering service.  
	\end{enumerate}
   
   The external ordering service is an alternative to the P2P approach currently utilised by Infinispan.  This service consists of a dedicated set of nodes acting as a replicated state machine which provides a total order value for any multicasts required by Infinispan nodes.  The rationale behind this approach is that the number of nodes required to reach a consensus on a message's total order is limited to the number of nodes in the ordering service.  Therefore, as the number of nodes participating in a transaction increases, the time required to reach a consensus remains constant, hence the problems associated with P2P protocols in partially replicated environments are circumvented.

    Prior to this research, the throughput capabilities of such a service were limited by the protocols available for replicating state between the nodes providing the ordering service.  Existing coordination services, such as Zookeeper \citep{Hunt:2010:ZWC:1855840.1855851} and Chubby \citep{Burrows:2006:CLS:1298455.1298487}, utilise Quorum based protocols for state machine replication.  Such protocols are advantageous as they do not block in the event of node crashes, however they are dependent on a 'leader' node for coordinating replication which becomes a performance bottleneck as the number of required replications increases.  Such protocols are less attractive for our ordering service, as the service requires a node's state to be replicated each time an ordering request is received and requests are expected to occur frequently.  
    
    An alternative approach to the Quorum based protocols, are group membership dependent atomic broadcast protocols.  Such protocols do not utilise a leader node and provide the best possible throughput and latency when no node crashes occur.  However, when node crashes do occur, message delivery to the application is blocked until the group membership service informs the participating nodes that a failure has occurred.  This blocking makes these protocols equally less attractive for use within an ordering service as a single service node crash will prevent the ordering service from providing a total order on Infinispan's multicast messages, which in turn prevents any transaction in the Infinispan cluster progressing.  

    Motivated by the limitations of these existing protocols, the second aspect of our research is the development of a hybrid atomic broadcast protocol that can be utilised for fault-tolerant state machine replication.  This protocol combines a deterministic atomic broadcast, which provides low-latency message delivery in the absence of node failures, and a probabilistic protocol for non-blocking message delivery in their presence; the latter guarantees atomicity with a probability close to 1.     
   
   Throughout this thesis we have utilised Infinispan as a basis for designing and implementing our solutions.  Infinispan was utilised because it is entirely open source and already provides support for coordinating ACID transactions via atomic multicasts.  Furthermore, given that this research was funded in its entirety by Red Hat, Inc who are responsible for developing Infinispan, our choice was natural.  
   
    \section{Thesis Contribution}
    The research presented in this thesis makes several key contributions:
    
	    \begin{enumerate}[label=\roman*]
	        \item An extensive background section that provides the prerequisite information required to understand the problem domain.  Of particular significance is the detailed breakdown of the Infinispan NoSQL database and how it addresses the challenges of coordinating distributed transactions in partially replicated environments.  
	        
	        \item A new system model, \textsf{AmaaS}, for coordinating distributed transactions in partially replicated environments and a new fault-tolerant atomic multicast protocol that has been designed specifically for \textsf{AmaaS}.  
	        
	        \item A hybrid atomic broadcast protocol, \textsf{ABcast}, which is designed for providing state machine replication within the \textsf{AmaaS} model.  \textsf{ABcast} provides low-latency message delivery in the absence of node failures and non-blocking message delivery in their presence, by utilising both a deterministic and probabilistic atomic broadcast protocol to deliver messages up the network stack.  
	        
	        \item An extensive performance evaluation of both the \textsf{AmaaS} model and the \textsf{ABcast} protocol.
	    \end{enumerate}
    
    \section{Thesis Structure}
         \begin{description}            
             \item[Chapter 2 - Background] \hfill \\
             Presents the key prerequisite information required to understand the problem domain.  
             
             \item[Chapter 3 - AmaaS] \hfill \\
             Introduces a new system model for coordinating partially replicated transactions, that we call Atomic Multicast as a Service - \textsf{AmaaS}.  This new model is inherently different from the P2P approach previously utilised by the Infinispan database, therefore we formalise a new fault-tolerant atomic multicast protocol, \textsf{SCast}, for coordinating transactions that utilises \textsf{AmaaS}.  
             
             \item[Chapter 4 - ABcast] \hfill \\
              Presents the rationale, design assumptions and important implementation details for the hybrid atomic broadcast protocol \textsf{ABcast}.  As well as detailing \textsf{AFC}, a bespoke flow-control protocol designed for \textsf{ABcast}.  
             
             \item[Chapter 5 - Probabilistic SCast] \hfill \\
             Explores the consequences of utilising the ABcast protocol for state machine replication between service nodes in the AmaaS model.  More specifically, it focuses on the potential repercussions of message miss-orderings at the service level and how they can impact client nodes that depend on the ordering service.  
             
             \item[Chapter 6 - Performance Evaluation] \hfill \\
             Provides a thorough performance evaluation of the \textsf{AmaaS} model compared to the existing P2P approach, as well as investigating the effect of utilising different atomic broadcast protocols within the \textsf{AmaaS} service.  Furthermore, we evaluate the performance of the \textsf{ABcast} protocol when node failures occur, in order to ascertain the effectiveness of the protocols non-blocking message delivery.  
             
             \item[Chapter 7 - Conclusions] \hfill \\
             Presents a summary of the findings presented throughout this document and speculates on potential future research made possible by our findings.  
         \end{description}