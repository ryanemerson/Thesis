\chapter{Performance Evaluation}\label{ch:perf_eval}
    \graphicspath{{Chapter6-PerformanceEvaluation/Figs/Vector/}{Chapter6-PerformanceEvaluation/Figs/}}
    
    This chapter provides a comprehensive performance evaluation of the key concepts introduced in this thesis.  Evaluation focusses on five issues: 
    \begin{enumerate}[label=\roman*]
    \item    The scalability of the \textsf{AmaaS} model over P2P.  
    
    \item    A performance comparison between \textsf{ABcast} and TOA when utilised in the context of \textsf{AmaaS}.
    
    \item    The performance of \textsf{ABcast} when requests are frequent over a long period of time.  
    
    \item    The probability $R$ of ordering correctness by \textsf{ABcast}, more specifically \textsf{Aramis}.
    
    \item    The effectiveness of \textsf{ABcast}'s non-blocking message delivery in the interim period between a node crashing and the GM protocol publishing a new view.  
    \end{enumerate}    

   
    The remainder of this chapter is structured as follows: First we detail an experiment that emulates Infinispan's distributed transactions, and is used to evaluate (i) and (ii) ($\S$ \ref{sec:emulated_transactions}).  This is followed by an experiment that replicates the inner workings of the \textsf{SCast} protocol, in order to simulate an \textsf{AmaaS} service operating at maximum capacity, which is used to evaluate (iii) and (iv) ($\S$ \ref{sec:infinite_clients_eval}).  Finally, we introduce an experiment that evaluates (iv) and (v) by crashing a node while \emph{abcast}s are sent between nodes ($\S$ \ref{sec:infini_crashed_node}).  

% Probing validation experiments    
%\section{DMC Validation}

\section{AmaaS}\label{sec:emulated_transactions}
	To test our hypothesis that the \textsf{AmaaS} model can improve the scalability of Infinispan's distributed transactions, we developed an experiment that emulates the workflow of these transactions by replicating the \emph{amcast} messages sent by Infinispan when executing total order transactions ($\S$ \ref{sec:to_commit}).  This experiment does not utilise Infinispan, or implement a basic transaction manager, rather it focuses purely on replicating the underlying communication stages required by Infinispan transactions.  
	
	Existing research \citep{Ruivo:2011:ETO:2120967.2121604} has already shown the benefits of utilising a total order protocol instead of 2PC, therefore our experiments concentrate on the performance of the underlying \emph{amcast} protocol used to coordinate these transactions.  
	
	In our experiments, if a new \emph{amcast} protocol can demonstrably increase throughput and reduce latency of \emph{amcast} messages as the number of destinations increase,  then we can infer that the scalability of the Infinispan system will be improved by adopting this protocol.  Therefore, if our experiments show that the \textsf{AmaaS} model consistently outperforms P2P, then we assume our hypothesis to be true. 
	
   In order to compare and contrast the performance of the \textsf{AmaaS} and P2P approach, it was necessary for two experiments to be created.  
   
   The first experiment was designed to evaluate the latency and throughput of both a \textsf{SCast} and \textsf{PSCast} service.  This experiment allows the performance of the \textsf{AmaaS} model to be evaluated, whilst also enabling the performance of the underlying \emph{abcast} protocols, which are utilised by the services for state machine replication, to be contrasted.  Both the \textsf{SCast} and \textsf{PSCast} services utilise a simplified version of  the \textsf{SCast} Protocol ($\S$ \ref{sec:scast_protocol}) to coordinate interactions between $c$-nodes and $s$-nodes.  

   The second experiment was designed to measure the performance of \emph{amcast} requests when utilising the P2P approach.  This experiment utilises the same workloads and parameters as the first experiment, however, as per the P2P model, no $s$-nodes are present and consequently there is no need for the \textsf{SCast} protocol.  Instead, the TOA protocol is executed directly between $c$-nodes when emulating transactions.  
   
   Utilising the same experiment structure and workloads across both sets of experiments allows us to compare the performance of the two system models across a consistent environment.  This consistency enables us to contrast the performance of the TOA protocol, when utilised in both the P2P model and the \textsf{SCast} service, with the \textsf{ABcast} protocol utilised by the \textsf{PSCast} service.  

	\subsection{Experimentation}\label{ssec:emulated_transaction_experiments}
	\subsubsection*{\textsf{SCast} and \textsf{PSCast} Services}
	We implemented our \textsf{AmaaS} services using the JGroups\citep{JGroups} framework with $n=2$ and $n=3$ $s$-nodes.  All nodes in the experiment utilised commodity PCs of \emph{3.4GHz Intel Core i7-3770} CPU and 8GB of RAM, running \emph{Fedora 20} and communicating over Gigabit Ethernet. The $s$-nodes and $c$-nodes utilised in our experiments are a part of a large university cluster, hence communication delays between nodes can be quite volatile as they are influenced by other network traffic and processes launched by other users.
	
	Our experiments are based upon a heavily modified version of an existing performance test available in the JGroups\citep{JGroups} framework, which mimics the partial replication of key/values in Infinispan\citep{Infinispan}.  In these experiments we utilise ten $c$-nodes in the same cluster, each of which emulates a transaction system which is reliant on an \textsf{AmaaS} service for transaction ordering.  Each $c$-node operates 25 concurrent threads to initiate and coordinate transactions, and a transaction $Tx$ involves a set $|Tx.dst| = 3,4,\ldots,10$ $c$-nodes; where $|Tx.dst|$ includes $Tx.c$. A thread coordinating a transaction starts its next transaction, $Tx'$, as soon as it executes a commit/abort decision for the currently active $Tx$. Thus, at any moment, $250$ transactions are in different stages of execution.  
	
	All of the emulated transactions consist purely of key/value write operations and thus require \emph{amcast} messages for coordination.  Infinispan's read requests ($get(k)$) are not emulated, as the retrieval of key/values occurs before $Tx.c$ \emph{amcast}s its $prepare(k)$ message, hence read operations have no baring on the performance of the underlying \emph{amcast} protocol.  
	
	Both the \textsf{SCast} and \textsf{PSCast} services utilise a modified version of the \textsf{SCast} protocol defined in section \ref{sec:scast_protocol} to dictate the interactions between $c$-nodes and $s$-nodes.  In our implementation $s$-nodes utilise message bundling to reduce the total number of \emph{abcast} messages required.  
	
    \textbf{\emph{Omission:}} Stage 1 of the \textsf{SCast} protocol has been omitted from this implementation because we only compare the performance of the two approaches in a crash-free scenario.  Our rationale for removing this stage, was that the fault-tolerance provisions described in \textsf{SCast} is only one possible solution for ensuring that the \emph{amcast} protocol can continue to execute in the event of the original coordinator crashing during a multicast and alternative solutions are not obliged to utilise this additional communication stage.  Furthermore, in our experiments we are comparing \textsf{SCast} to the \textsf{TOA} protocol which does not implement any mechanism to cope with a crashed message originator, therefore removing Stage 1 of \textsf{SCast} protocol makes for a fairer comparison of the two protocols.  
	
	\textbf{Experiment Workflow:} The workflow of a transaction in our experiments is as follows:
    \begin{enumerate}
        \item    A coordinator thread submits its \emph{amcast} request for $Tx$, denoted as $req(Tx)$, with some $s$-node; who stores the request in FIFO order within its ARP. 
        
        \item    The $s$-nodes \emph{Send} thread retrieves requests stored in its ARP and places them into a message bundle $mb$, which can have a maximum payload of $1kB$ \footnote{In the experiments that utilise the \textsf{ABcast} protocol, we \emph{pad} the contents of the message bundle to ensure that it is always equal to $1kB$.  This ensures that all messages \emph{abcast} by the protocol are approximately the same size, which increases the accuracy of the DMC's predictions at the expense of redundant bandwidth.}, then \emph{abcast}s $mb$ to all other $s$-nodes.  
        
        \textbf{Note:} If there exists no requests in the ARP, then the \emph{Send} thread waits for it to become non-empty before initiating the next $mb'$.  Hence, the number of requests bundled in any $mb$ varies depending on the arrival rate of requests. 
        
        \item    Once $req(Tx)$ has been \emph{abcast} to all $s$-nodes, a response message, $Rsp(Tx)$ it is sent to $Tx.c$ who disseminates this message to $Tx.dst$ as $mcast(Tx)$.  
        
        \item    When all $d \in Tx.dst$ have received and delivered $mcast(Tx)$, as per the delivery conditions of the \textsf{SCast} protocol, the transaction is considered complete and the coordinator thread can start executing $Tx'$.  
    \end{enumerate}	
	
    In our experiments that utilise \textsf{ABcast} (\textsf{PSCast} service), an additional phase is required before the experiments can begin.  Prior to accepting requests from $c$ nodes, $s$-nodes must participate in an initialisation period that lasts approximately 1-2 seconds.  During this period, the clocks of the $s$-nodes are synchronized and each $s$-node broadcasts $10^3$ \emph{probe} messages, with a payload of $1kB$, to all other $s$-nodes.  The purpose of these probe messages is to record the $NT_P$ latencies required by \textsf{ABcast}'s DMC.  
    
    Finally, all of our experiments with \textsf{ABcast} (\textsf{PSCast} Service) utilise the the following constant values.  The DMC utilises $R=0.9999$ ($\S$ \ref{ssec:dmc}), and AFC utilises $\delta_{min}$ and $\delta_{max}$ values equal to $1ms$ and $10ms$, respectively ($\S$ \ref{sec:afc_protocol}).  
	
	\subsubsection*{P2P}
	In order to test the performance of P2P total order transactions we repeated the experiments detailed above, however, as per the P2P model, all $c$-nodes coordinate transactions between themselves without utilising any $s$-nodes.  In these experiments, a transaction is considered complete when it has been successfully \emph{amcast} to all $d \in Tx.dst$ by the P2P protocol; where success is defined as all correct destinations delivering the \emph{amcast} message. 
	
	\textbf{Note:} The same cluster of machines were used for both the P2P and \textsf{AmaaS} experiments to ensure a fair comparison between protocols.   
	
	\subsection{Results}\label{sec:AmaaS_results}
	Our performance evaluation focuses on the comparison of the TOA protocol, being utilised in a traditional P2P scenario (\emph{TOA-P2P}), with two different \textsf{AmaaS} services that utilise the \textsf{SCast} protocol.  The \textsf{SCast} service utilises the deterministic protocol TOA for state machine replication, whilst the \emph{PSCast} service utilises the probabilistic protocol \textsf{ABcast}, hence we refer to these two services as the \emph{TOA-Service} and \emph{ABService}.  
    
    The performance of all three approaches is measured based upon the average transaction latency and throughput rate. In both the \emph{TOA-Service} and \emph{ABcast-Service}, latency is measured as the time elapsed between a $c$-node's initial transmission of $req(Tx)$ to some $s$-node, and \textbf{all} members of $Tx.dst$ delivering $mcast(Tx)$ to the experiment application. In TOA-P2P, latency is measured as the time taken for all $Tx.dst$ to deliver $Tx$ to the experiment application. For both approaches, throughput is measured as the average number of \emph{abcast}s delivered by the experiment application per second at each $c$-node.
	
	\textbf{Note:} All of our experiments were conducted in isolation in order to prevent any side effects caused by simultaneously executing multiple experiments on the same cluster, however we conducted all experiments over approximately the same time period to ensure that the network was under similar loads for all of our experiments. 
	
	Figures \ref{fig:LatencyGraph} and \ref{fig:ThroughputGraph} show the latency and throughput results for our experiments, with $2N$ and $3N$ representing an \textsf{AmaaS} service that consists of two and three, $s$-nodes respectively.  Each plot on the graph is an average of three \emph{crash-free} trials; where a trial consists of each $c$-node completing $10^4$ transactions for a specific value of $|Tx.dst|$. Thus, in all three trials the \emph{TOA-Service} and \emph{ABService} each receive a total of $10^5$ \emph{amcast} requests. In TOA-P2P, each $c$-node initiates $10^4$ TOA executions between its peers ($10$ $c$-nodes $\times 10^4 = 10^5$).  
	
	Concerning \textsf{AmaaS} performance, Table \ref{table:emulated_transaction_averages} shows the average number of client requests received, the average number of \emph{abcast} messages sent and the average number of requests bundled into each \emph{abcast}, based upon all of our experiments that utilised a \textsf{AmaaS} service.  All of theses average values are calculated based upon the statistics recorded by each $s$-node that was utilised during our experiments. 
	
    \begin{table}[h]
  \begin{center}
    \begin{tabular}{|l|c|c|c|}
    \hline
    Experiment & $\#$ Client Requests  & $\#$ \emph{abcast}s & Bundle Size \\ \hline \hline
    ABService-2N     & 50000    &    12763.4    &    4 \\ \hline
    TOA-Service-2N  & 50000    &   16632    &   3 \\ \hline
    ABService-3N     & 33333.3 &    13416.4  &   2.5 \\ \hline
    TOA-Service-3N  & 33333.3 &    13507.8 & 2.5 \\ \hline
    \end{tabular}
    \caption{Average Node Statistics for Emulated Transaction Experiments}
    \label{table:emulated_transaction_averages}
  \end{center}
\end{table}	
	
    Table \ref{table:emulated_transcation_aramis_deliveries} shows the performance of the \textsf{ABcast} protocol in both the ABService-2N and 3N experiments.  It shows the average number of \emph{abcast}s sent per node and the average number of these messages that were delivered by the Aramis protocol, as well as providing the total percentage of \emph{abcast}s that were delivered via Aramis.  Furthermore, this table details the ratio of $s$-nodes that delivered an \emph{abcast} via Aramis compared to the total number of $s$-nodes utilised.  For example, in the case of ABService-2N we performed $24$ experiments, therefore we have statistics for $48$ $s$-nodes and our records show that only $3$ of these nodes utilised Aramis to deliver one or more \emph{abcast} messages.  
    
    The very small number of \textsf{Aramis} deliveries is understandable as $\Delta_m$ of \textsf{Aramis} is estimated pessimistically and no crashes occur.  In fact, it is surprising that some \emph{abcast}s were indeed delivered by \textsf{Aramis} faster than \textsf{Base} and more discussions on this aspect are presented in subsection \ref{ssec:emulated_eval}.  
	
	\begin{table}[h]
	  \begin{center}
	    \begin{tabular}{|l|c|c|c|c|}
	    \hline
	    Experiment  & $\#$ \emph{abcast}s & Nodes Affected &  Avg Aramis Deliveries & $\%$ Aramis Deliveries \\ \hline \hline
	    ABService-2N & 12763.4 & 3:48   & 10.8  & $0.085\%$  \\ \hline
	    ABService-3N & 13416.4 & 30:72 & 15.3  & $0.114\%$ \\ \hline
	    \end{tabular}
	    \caption{Average ABcast Statistics per Node}
	    \label{table:emulated_transcation_aramis_deliveries}
	  \end{center}
	\end{table}	
	
	\begin{figure}[h]
	 % \centering
	 \includegraphics[width=\textwidth,height=\textheight,keepaspectratio, clip, trim={2cm 3.25cm 2cm 3cm}]{Latency2}
	 \caption{AmaaS Latency Comparison}
	 \label{fig:LatencyGraph}
	\end{figure}
	
	\begin{figure}[h]
	% \centering
	 \includegraphics[width=\textwidth,height=\textheight,keepaspectratio, clip, trim={2cm 3.25cm 2cm 3cm}]{Throughput2}
	 \caption{AmaaS Throughput Comparison}
	 \label{fig:ThroughputGraph}
	\end{figure}	
	
	\clearpage
    \subsection{Evaluation}\label{ssec:emulated_eval}
    This section is split into three distinct subsections.  First we directly compare the performance of the \textsf{AmaaS} service and the P2P approach with both experiments utilising the same TOA protocol.  We then evaluate the performance of the ABService in contrast with the previous two approaches, focusing on the differences between the performance of the ABcast and TOA based service.  Finally, we evaluate the performance of \textsf{ABcast}, focusing on how often the \textsf{Aramis} protocol was utilised to deliver messages and its ability to maintain ordering correctness.  
    
    \subsubsection*{AmaaS vs P2P}
	In Figure \ref{fig:LatencyGraph} we can see that when $|Tx.dst| \geq 4$, TOA-P2P's \emph{abcast} latencies increase considerably when compared to the two TOA-Service experiments.  With TOA-P2P experiencing approximately a $25\%$ and $50\%$ increase in average latency when compared to TOA-Service-3N and TOA-Service-2N respectively.  Thus, indicating that \emph{amcast}ing is best provided as a service as the number of clients involved in a transaction increases. Comparing throughput in Figure \ref{fig:ThroughputGraph} leads to similar conclusions, with the steady throughput observed as $|Tx.dst| \rightarrow 10$ also suggesting an absence of node saturation.  
	
	TOA-P2P's superior performance when $Tx.dst < 4$ can be attributed to the additional stages involved when utilising the \emph{AmaaS} model.  For example when TOA-Service utilises two $s$-nodes ($2N$) the following stages are required: $Tx.c$ sends a request, the \emph{multicast service} \emph{abcast}s it with $|m.dst| = 2$ to all $s$-nodes and returns it to $Tx.c$, who must then multicast $mcast(Tx)$ to $Tx.dst$.  Ignoring the individual message cost of each stage the total number of stages is four, whereas in TOA-P2P the only step required is the \emph{amcast}ing of $Tx$.  So although $|m.dst|$ for each \emph{amcast} is less in TOA-Service ($|m.dst| = 2$) than TOA-P2P ($|m.dst| = 3$), the overhead of sending a request to the \emph{multicast service} and back is much greater than the savings offered by reducing $|m.dst|$ by one node.  However, as $|Tx.dst|$ increases, the overhead of TOA-P2P's increased $|m.dst|$ becomes significant, to the point where TOA-Service's additional communication stages becomes less of an overhead than the cost of TOA-P2P \emph{amcat}ing to a large $m.dst$.  
	
    \subsubsection*{ABService vs TOA-Service}
    In Figure \ref{fig:LatencyGraph} we can see that the latencies encountered by the ABService-2N and TOA-Service-2N experiments are very similar, regardless of the number of clients involved in a transaction, with the maximum difference between any two plots being no greater than $0.3$ milliseconds.  Interestingly, our experiments show that in the majority of experiments ($5/8$), the ABService outperforms TOA-Service.  This superior performance can be attributed to a combination of two factors: the number of requests that are bundled on average per \emph{abcast} and the overall message cost associated with the underlying \emph{abcast} protocol.  
    
    The average number of client requests bundled into a single \emph{abcast} can play a decisive role in the latency and throughput of a \textsf{AmaaS} service as the higher the average bundle rate, the lower the total number of \emph{abcast}s required.  As the \emph{abcast}ing of requests between $s$-nodes is the most expensive operation, in terms of bandwidth and latency in the \textsf{AmaaS} model, it is self-evident that reducing their frequency will reduce the average latency encountered by client requests, therefore reducing the total duration of a transaction.  
    
    Table \ref{table:emulated_transaction_averages} shows that the average bundle rate for the ABService-2N was $4$ messages, whilst it was only $3$ for TOA-Service-2N.  Therefore, on average a node in TOA-Service-2N sends $\approx 3869$ more \emph{abcast}s then its counterpart ABService-2N, which partially explains the difference in performance between the two approaches.  
    
    The difference in overall message cost between the two \emph{abcast} protocols is a consequence of the two different approaches to solving \emph{abcast} and the optimisations present in the \textsf{ABcast} protocol ($\S$  \ref{ssec:atomic_broadcast} $\&$ \ref{ssec:base_ack_piggyback}).  The \textsf{ABcast} protocol piggybacks any outstanding message acknowledgements on subsequent message broadcasts, enabling \emph{abcast}s to be executed in a single phase when all nodes are frequently sending \emph{abcast}s.  Whereas, the JGroups implementation of the TOA protocol does not implement any optimisations, and thus, each broadcast always consists of two phases, therefore increasing the average latency encountered by transaction requests.  
	
	Correspondingly, it is possible to observe that the average and maximum difference between the latencies encountered in the ABService-3N and TOA-Service-3N experiments is greater than that observed when $N = 2$.  The improving performance of the ABService can be attributed to the \textsf{ABcast} optimisations becoming more effective as the number of $s$-nodes increase.  For example, if $N = 3$ and \textsf{ABcast} sends a broadcast, the total message cost for that single \emph{abcast} is only $2$ unicasts, whereas with TOA the total cost is $6$ unicasts.  Clearly, such an optimisation will have a positive effect on the performance of the ABService implementation, especially when service requests are evenly distributed amongst $s$-nodes and are arriving frequently which is ideal for the \textsf{ABcast} optimisations.  
	
    Interestingly, in Table \ref{table:emulated_transaction_averages} we can see that the average bundle rate of ABService-3N and TOA-Service-3N are almost the same, yet the difference between the observed latencies in the two approaches has increased.  This suggests that in these experiments the average bundle rate has no significant impact on the performance of the two approaches.  
    
    The large difference between the average bundle rate observed in ABService-2N and 3N, is a direct consequence of the DMC's calculations and how AFC ($\S$ \ref{sec:afc_protocol}) manages broadcast rates.  Recall that the delay imposed by AFC, for an \emph{abcast} message, increases when latencies start to exceed the previously calculated $x_{mx}$ value, and decreases to $\delta_{min}$ when no such latencies are observed.  When $2$ $s$-nodes are utilised, the observed $x_{mx}$ is typically lower than 3 $s$-nodes, as the number of unicasts sent between $s$-nodes is less; hence the probability of large delays being observed is reduced.  The smaller the average $x_{mx}$ value, the more susceptible the system is to delays periodically exceeding $x_{mx}$.  Therefore, when $2$ $s$-nodes are utilised the probability of the calculated AFC delay regularly exceeding $\delta_{min}$ increases, which in turn reduces the node's broadcast rate.  Consequently, the number of requests which can accumulate between \emph{abcast}s will increase, and hence the average bundle rate also increases.  When $3$ $s$-nodes are utilised, the DMC's observations are typically more stable, resulting in less \emph{outlier} latencies being recorded and the broadcast rate being more stable; hence an average bundle rate that is approximately the same as the TOA-Service-3N.  
	
	The throughput of the ABService and TOA-Service for both $2N$ and $3N$ follows a very similar pattern to that observed when analysing their latencies.  This is not surprising as the average transaction latency has a direct impact on the average rate of throughput.  Combining the results shown in Figures \ref{fig:LatencyGraph} and \ref{fig:ThroughputGraph}, it is clear to see that the ABService provides comparable performance to that of the TOA-Service and that both of these \textsf{AmaaS} solutions consistently outperform TOA-P2P when $Tx.dst > 3$.  
	
	\subsubsection*{ABcast}
	In Figure \ref{table:emulated_transcation_aramis_deliveries} we can see that only $3$ of the $48$ nodes utilised by ABService-2N delivered an \emph{abcast} via the \textsf{Aramis} protocol, with the average number of messages being $\approx 11$, only $0.085\%$ of all messages.  Hence, the $\Delta_m$ value calculated by the DMC was sufficient for  $99.915\%$ of \emph{abcast}s.  The results of the ABService-3N experiments shows that as the number of $s$-nodes increased,  the total number of \textsf{Aramis} deliveries also increased.  Almost $50\%$ of nodes delivered at least one message via \textsf{Aramis}, with an overall average of $\approx 16$ messages per node.  Although this is a large increase in the number of nodes requiring \textsf{Aramis}, the protocol still only accounts for $0.114\%$ of all \emph{abcast}s sent.  
	
	The increase in \textsf{Aramis} deliveries as the number of $s$-nodes increase can be attributed to the DMC recording each latency anomalously (without regard for source of the message) and calculating $\Delta_m$ based upon these latencies.  In the experiments where $n=2$, we know that all of the latencies recorded by node $Ns_1$ will be from messages originating at $Ns_2$.  Therefore, when node $Ns_1$ broadcasts message $m$, it is guaranteed that the calculated $\Delta_m$ has been calculated utilising latencies representative of $Ns_2$'s past performance.  Whereas, when $n=3$, $Ns_1$ will have calculated $\Delta_m$ based upon latencies recorded from both $Ns_2$ and $Ns_3$, therefore it is possible that if $Ns_3$ is slower than $Ns_2$, the latencies calculated from $Ns_2$ will dilute the larger latencies recorded from messages originating at $Ns_3$.  Thus, the calculated $\Delta_m$ could be smaller than the value required by the slower node $Ns_3$.  
	
	\textbf{Note:} None of the experiments that delivered a message via \textsf{Aramis} suffered an \textsf{ABcast} ordering violation and hence no SCast ordering violations occurred at any client nodes.  Furthermore, we repeated our experiments with delivery condition $D1_B$ of the \textsf{Base} protocol disabled, which causes all \emph{abcast}s to be delivered via \textsf{Aramis}, in order to evaluate the accuracy of $\Delta_m$.  We found that, for both $n=2$ and $n=3$, the calculated $\Delta_m$ was sufficient for all $s$-nodes to deliver messages without a single ordering violation occurring.  As expected, latencies were large, and they were so large that a single experiment (emulating $10^5$ transactions) took several minutes to complete.  Obviously such large latencies are not practical, however these experiments provide evidence of $\Delta_m$'s ability to prevent ordering violations.  
		
	\subsection{Summary}
	When deploying a large-scale distributed transaction system that executes transactions which span several nodes ($|Tx.dst| > 3$), higher throughout and lower-latency can be achieved by utilising the \textsf{AmaaS} model for \emph{amcast} messages.  Furthermore, such a service can provide non-blocking \emph{amcast}s when the \textsf{ABcast} protocol is utilised for state machine replication, whilst maintaining similar levels of performance to when a GM based protocol is utilised.  

\section{ABcast - Infinite Clients for Extreme Load Conditions}\label{sec:infinite_clients_eval}
    In the previous section, we tested the performance of the \textsf{AmaaS} approach whilst utilising the \textsf{ABcast} protocol.  Our results showed, that the \textsf{Aramis} protocol was rarely required to deliver messages, accounting for only $0.015\%$ and $0.114\%$ of messages, when the number of $s$-nodes was two and three respectively.  However, in these experiments the total number of \emph{abcast} messages was, on average, relatively low for each node; typically less than $2 \times 10^4$.  Furthermore, each $s$-node's rate of \emph{abcast}s would vary depending on the restrictions of the AFC protocol and the rate at which requests were being received by $c$-nodes.  
    
    Due to the number of client nodes being relatively small, it is probable that at times an $s$-node's ARP could have been empty.  Therefore, in order to test the performance of \textsf{ABcast} under extremely heavy loads, it was necessary for a new experiment to be developed.  The purpose of these experiments are two fold.  First, they allow us to measure how often \textsf{Aramis} is required to deliver messages and the frequency of order violations.  Secondly, they allow us to monitor the values calculated by the DMC during high levels of network load and determine their effect on the resulting $\Delta_m$.  
    
    In order to test the performance of \textsf{ABcast} under heavy loads, we could simply increase the number of client nodes that were used in our previous experiment, however this would require a large amount of resources and would be cumbersome to orchestrate.  Furthermore, such an approach does not guarantee that the ARP of a given $s$-node will always have a request to process.  
    
    We propose a new experiment, which we refer to  as an \emph{infinite client system} as it represents the performance of \textsf{AmaaS} ordering service if each $s$-node always has a full ARP.  This experiment does not utilise client nodes at all, instead, it simply consists of $n$ nodes initiating \emph{abcast}s \emph{as fast as} \textsf{AFC} permits.  This is the same as the steps required by \textsf{SCast} for state machine replication, however we do not have the overhead of maintaining the data structures required by \textsf{SCast} at each node; \emph{i.e.} $order\_history[]$.  Therefore the delay between subsequent \emph{abcast}s will be less in this experiment, hence the \textsf{ABcast} protocol will be under a heavier load in these experiments than is possible in a \emph{complete} \textsf{SCast} implementation. 
    
    \subsection{Experimentation}\label{ssec: infinite_experimentation}
    The infinite client experiment was implemented using the JGroups framework and the same \textsf{ABcast} implementations as the experiments detailed in $\S$ \ref{ssec:emulated_transaction_experiments}.  Furthermore, our experiments utilised the same computer cluster and specification of machine as our previous experiments.  
    
    An individual \emph{infinite client} experiment consists of $3$ nodes sending $10^6$ \emph{abcast}s between themselves; with each individual node sending $\frac{10^6}{n}$ messages with a payload of $1kB$.  The workflow of our experiments is as follows:
    
    \begin{enumerate}
        \item    A node broadcasts its requests as fast as possible using a single thread, which represents the \emph{sender} thread utilised in \textsf{SCast}
        
        \item    As soon as a message has been sent, another \textsf{ABcast} is initiated; where the sending of a message $m$ consists of $m$ being sent down the JGroups stack, processed and delayed by AFC, before being unicast to all $n$ nodes.  
        
        \item    An experiment is considered complete when each node has delivered $10^6$ messages, or if one or more order violations ($\#violations$) has occurred, then ($10^6 - \#violations$) \footnote{As none of our experiments maintain a state at the application level, \emph{abcast}s that cause order violations are not \emph{delivered} to the application, instead their occurrence is simply recorded.}.  
    \end{enumerate}
    
    For all of our experiments the \textsf{ABcast} protocol used the following constant values: $R = 0.9999$, $\delta_{min} = 1ms$ and $\delta_{max} = 10ms$.  Furthermore, we utilise the same initialisation period from the \textsf{AmaaS} experiments.  
    
    \subsection{Results}
The experiment detailed in $\S$ \ref{ssec: infinite_experimentation} were executed a total of ten times, utilising the same machines for each experiment.  Table \ref{table:infinite_clients_rejections} presents the results of each of these experiments based upon each node's individual performance as well as the performance of the cluster as a whole; where $Ns_1, Ns_2, Ns_3$ correspond to the values recorded by an individual node and we define the cluster as being the combined performance of $\{Ns_1,Ns_2,Ns_3\}$.  For each node in an experiment, we show the total number of \emph{abcast}s that were delivered by \textsf{Aramis} and in brackets the number of order violations.  We also show the total number of \emph{abcast}s delivered by \textsf{Aramis} across the cluster, and the percentage of all \emph{abcast}s that are delivered by \textsf{Aramis}.  
    
\begin{table}[p]
  \begin{center}
  \renewcommand{\arraystretch}{1.3}
   \begin{tabular}{|l|c|c|c|c|c|}
    \hline
    Experiment & $Ns_1$ & $Ns_2$       & $Ns_3$      & Total    & $\%$ of all \emph{abcast}s \\ \hline \hline
    1          & 9220, (0)  & 7929, (0)  & 6434, (0)  & 23538 & 2.36 \\ \hline
    2          & 3348, (0)  & 4555, (0)  & 5008, (0)  & 12911 & 1.29 \\ \hline
    3          & 4496, (0)  & 4920, (0)  & 1952, (0)  & 11368 & 1.14 \\ \hline
    4          & 5832, (0)  & 6439, (0)  & 4801, (0)  & 17072 & 1.71 \\ \hline
    5          & 5320, (0)  & 5757, (0)  & 4066, (0)  & 15143 & 1.51 \\ \hline
    6          & 4181, (0)  & 3286, (0)  & 4157, (0)  & 11624 & 1.16 \\ \hline
    7          & 1743, (0)  & 2237, (0)  & 2235, (0)  & 6215   & 0.62 \\ \hline
    8          & 4188, (0)  & 1846, (0)  & 5421, (0)  & 11455 & 1.15 \\ \hline
    9          & 5621, (0)  & 4242, (0)  & 5291, (0)  & 15154 & 1.52 \\ \hline
    10        & 2953, (0)  & 5014, (0)  & 3192 , (0) & 11159 & 1.12 \\ \hline \hline
    Total    &46902, (0) &46225, (0) &42557, (0) &135684 & 1.36\\ \hline
    \end{tabular}
    \caption[Aramis deliveries for Infinite Clients - $\rho_{min}$ = 1]{Aramis deliveries (Order Violations) for infinite clients - $\rho_{min}$ = 1}
    \label{table:infinite_clients_rejections}
  \end{center}
\end{table}
    
    Table \ref{table:infinite_clients_aramis_latencies} presents the average delivery latency encountered by all \emph{abcast}s sent via \textsf{ABcast} (including those delivered by \textsf{Aramis}), as well as the average $\Delta_m$ value calculated by each node.  Each node records its delivery delay as $Dt_m - m.ts$, where $m.ts$ is the timestamp allocated to an \emph{abcast} message $m$ when an \emph{abcast} is initiated and $Dt_m$ is the time at which $m$ is passed upto the application.  The average $\Delta_m$ value is recorded using a given node's calculations of $\Delta$ not those recorded by others, hence $Ns_1$'s average is calculated using only $\Delta$ values calculated by $Ns_1$'s DMC.  Therefore, the \textquoteleft{}overall' entry in the table provides the average $\Delta$ value of all nodes in the cluster.  
    
\begin{table}[p]
  \begin{center}
  \renewcommand{\arraystretch}{1.3}
   \begin{tabular}{|l|c|c|c|}
    \hline
    Node      & Avg Delivery Latency (ms) & Avg $\Delta_m$ (ms) \\ \hline \hline
    $Ns_1$   & $21.48$                           & $710.34$                   \\ \hline
    $Ns_2$   & $23.47$                           & $687.29$                  \\ \hline
    $Ns_2$   & $25.45$                           & $767.74$                   \\ \hline \hline
    Overall   & $23.47$                           & $721.79$                 \\ \hline
    \end{tabular}
    \caption{Average \textsf{ABcast} Latencies and Calculated $\Delta_m$ - $\rho_{min}$ = 1}
    \label{table:infinite_clients_aramis_latencies}
  \end{center}
\end{table}       

    \subsection{Evaluation}
    In Table \ref{table:infinite_clients_rejections} we can see that out of all $10^7$ messages, only $1.36\%$ of \emph{abcast}s were delivered by \textsf{Aramis}.  Furthermore, out of these $135684$ \textsf{Aramis} deliveries there was not a single order violation, therefore \emph{ABcast}'s guarantees were maintained even when the rate of requests was very high.  This lack of order violations implies that the calculated $\Delta_m$ is sufficiently large to prevent messages being missed, whilst still being small enough for some \emph{abcast}s ($1.36\%$) to be delivered via \textsf{Aramis} before the \textsf{Base} protocol could complete.  Thus, for $1.36\%$ of \emph{abcast}s the \textsf{ABcast} protocol reduces latency and prevents message blocking even in the absence of node failures, when compared to traditional GM based protocols.  Finally, the lack of order violations indicates that the protocol is able to handle a large number of \emph{abcast} requests without compromising on message ordering.  
       
    Correspondingly, Table \ref{table:infinite_clients_aramis_latencies} shows that the average delivery latency encountered by \emph{abcast} messages remains low even when the network is heavily loaded.  Furthermore, it shows that the average $\Delta_m$ value remains below $800ms$ for each node.  
    
    \textsf{ABcast}s ability to provide to low-latency message delivery in such conditions is crucial, as the speed of the \emph{abcast} protocol utilised in an \textsf{AmaaS} service ultimately determines the response time for each client request.  More significantly, the low average $\Delta_m$ value shows that, even under the heaviest of loads, the DMC is able to calculate an average $\Delta_m$ that is sub $1$ second and still deliver all messages without a single order violation.  This is a \textbf{\emph{vital}} result, because if the $\Delta_m$ value became increasingly large as the load increased, $\Delta_m$ would start to exceed the typical delay required by the GM service to publish a new view after a node crash, therefore rendering our hybrid approach redundant.  
    
    \subsection{Summary}
    The \textsf{ABcast} protocol is capable of providing low-latency \emph{abcast}s over a sustained period of time in conditions representative of those found in an \textsf{AmaaS} service.  In such conditions, the DMC consistently calculates a $\Delta_m$ value that is small enough to outperform GM services, whilst being sufficiently large to ensure that no violations of \emph{abcast} guarantees occur when messages are delivered by \textsf{Aramis}.  
    
\section{ABcast - Fault Tolerance}\label{sec:infini_crashed_node}
    In our previous experiments with \textsf{ABcast} we have evaluated the performance of the protocol in the context of an \textsf{AmaaS} service where no node failures occur.  However, as \textsf{ABcast} has been designed to compliment the low-latency performance of GM protocols, by allowing for non-blocking message delivery when node crashes occur, it is necessary to ensure that $\Delta_m$ is sufficiently small for messages to be delivered in the interim period between a node crash and the GM service publishing a new view. 
    
    Ultimately, if the GM service is able to publish a new view before any messages are delivered via the \textsf{Aramis} protocol, then the hybrid approach we have taken is unnecessary.  In such a case, a traditional GM based protocol would be more suitable as order violations are not possible.  Therefore in order to determine the effectiveness of \textsf{ABcast}'s hybrid approach, it was necessary to create an experiment that monitors the number of messages, if any, that are delivered by \textsf{ABcast} in the interim period between a node crashing and the GM service publishing a new view.
    
    Such an experiment also enable us to explore the impact of utilising different values for \textsf{ABcast}'s configuration parameters, such as $\rho_{min}$ and $R$, on the number of messages delivered in this interim period.  More specifically, these experiments allow us to explore the impact of these configurations parameters on the average $\Delta_m$ value calculated by a node and how these variations impact the observed number of order violations.  
    
    \subsection{Experimentation}\label{ssec:crash_experiment}
    In order to test the performance of \textsf{ABcast} when a node crashes, we reuse the experiments detailed in $\S$ \ref{ssec: infinite_experimentation}.  However, in these experiments, instead of all $3$ nodes sending a total of $10^6$ \emph{abcast}s, only $2$ of the nodes complete their broadcasts.  The third node, $Ns_3$, is crashed after sending $50000$ \emph{abcast}s.  
    
    \textbf{Note:} As JGroups is implemented in the Java programming language, we crash $Ns_3$, by crashing the underlying Java Virtual Machine (JVM), not the physical machine.  
    
    In order to understand this experiment and why crashing the underlying JVM is necessary, it is important to recall the design of JGroup's GMS and associated \emph{failure detection} protocols presented in section \ref{ssec:jgroups_gms}.  Recall that the \emph{failure detection} protocol \texttt{FD\_SOCK} is particularly effective at detecting node crashes; with crashes typically detected within seconds.  Therefore, in order for \textsf{ABcast} to deliver messages before the GMS protocol becomes aware of a node crash, the calculated $\Delta_m$ would need to remain relatively small ($\lesssim 2$ $seconds$) throughout our experiments.  
    
    Due to \texttt{FD\_SOCK}'s use of Java shutdown hooks, it was not possible for the crashed node in our experiments to be exited as a normal Java application; as this would result in the terminating node sending a leaving message to all members in the view and alerting GMS almost instantly that the node was leaving the current view.  Clearly such a leaving message cannot be sent when a node is crashed unintentionally.  Therefore, it was necessary for us to terminate the JVM in the most disruptive manner possible, in order to replicate the untimely occurrence of a real node crash.  We achieved this by using reflection to access the \emph{sun.misc.Unsafe} api and crash the JVM.  The code used to crash the JVM is shown below:
    
    \noindent
    \begin{minipage}{\linewidth}
        \hfill
	    \begin{lstlisting}
	            Field theUnsafe = Unsafe.class.getDeclaredField("theUnsafe");
	            theUnsafe.setAccessible(true);
	            ((Unsafe) theUnsafe.get(null)).getByte(0);
	    \end{lstlisting}
	    \hfill
	\end{minipage}

    As previously stated, we crash the node $Ns_3$ after it has initiated $50000$ \emph{abcast} requests.  Therefore, we consider each experiment to be complete when both $Ns_1$ and $Ns_2$ have delivered $(666666 + 50000 - \#violations)$ \emph{abcast}s.  For all of our experiments, we utilise the following AFC values $\delta_{min} = 1ms$ and $\delta_{max} = 10ms$.  We execute our experiments utilising $\rho_{min} = 1,2,3$ and $R=0.9999$ in order to determine the effect of increasing $\Delta_m$ on the number of messages delivered before the GM service publishes a new view and the number of order violations.  Similarly, we also execute our experiments utilising $\rho_{min} = 1$ and $R=0.99999$, to see the effect of increasing $R$ on $\Delta_m$ and the number of ordering violations.  
    
    Once again, we utilise the same initialisation period for \textsf{ABcast} as in our previous experiments.  
    
    \subsection{Results}
    Tables \ref{table:crashed_node_rho1}, \ref{table:crashed_node_rho2} and \ref{table:crashed_node_rho3} show the performance of the \textsf{ABcast} protocol in the experiments described in \ref{ssec:crash_experiment}, when $\rho_{min}$ is equal to $1, 2$ and $3$, respectively.  With each table showing the results of ten experiments that were executed with the specified $\rho_{min}$ value.  Each of these tables, show the average $\Delta_m$ value calculated for messages originating at both $Ns_1$ and $Ns_2$, as well as the total number of \emph{abcast}s, $\#abcast$, delivered by \textsf{Aramis} in the interim period between node $Ns_3$ crashing and the GM publishing a new view \footnote{If a column contains $-$ it indicates that no \textsf{Aramis} deliveries occurred before GMS detected $Ns_3$'s crash.}.  Furthermore, the value in brackets next to this total represents the number of order violations that occurred in the interim period.  Finally, $\#abcast$ shows the throughput gain provided by utilising the probabilistic \textsf{Aramis} protocol, as these \emph{abcast}s would not have been delivered until GMS detected $Ns_3$'s crash if a GM based protocol had been used for \emph{abcast}ing.   

    Table \ref{table:crashed_node_R.99999} shows the performance of \textsf{ABcast} in the same experiments, but with $\rho_{min} = 1$ and the constant $R = 0.99999$.  The fields and columns presented in this table are equivalent to those describe above.  
    
    \begin{table}[h]
  \begin{center}
  \renewcommand{\arraystretch}{1.5}
    \begin{tabular}{|c|c|c|c|c|}
    \hline
    \multirow{2}{*}{$\rho_{min}$} & \multirow{2}{*}{$R$}    & \multirow{2}{2cm}{$\#$ Violation Free Runs} & \multicolumn{2}{|c|}{$\#$ Violations} \\ \cline{4-5}
                                 &              &                   & $Ns_1$   & $Ns_2$             \\ \hline \hline
    3                           & 0.9999  & $10/10$    & $-$        & $-$                 \\ \hline
    2                           & 0.9999  & $9/10$      & $-$        & $\frac{1}{19485}$ \\ \hline
    \multirow{2}{*}{1} & \multirow{2}{*}{0.9999} & \multirow{2}{*}{$8/10$} & $-$ & $\frac{1}{12483}$ \\ 
                                 &              &                   & $-$        & $\frac{1}{10544}$ \\ \hline
    1                           &0.99999 & $9/10$      & $-$        & $\frac{1}{17016}$ \\ \hline
    \end{tabular}
    \caption{Summary of $\rho_{min}$ and $R$ when node crashes occur}
    \label{table:crashed_node_summary}
  \end{center}
\end{table}    
    
    Table \ref{table:crashed_node_summary} provides a summary of all of these previous tables, with each set of experiments represented as a single row and being uniquely identified by the combination of $R$ and $\rho_{min}$ values used in the experiments.  For each experiment, we show the number of experiments that encountered no order violations over the total number of experiments, and in experiments where violations did occur we present the number of order violations over the number of successful \textsf{Aramis} deliveries that occurred before GMS detected $Ns_3$'s crash\footnote{In Table \ref{table:crashed_node_summary}, $-$ indicates that no \textsf{Aramis} order violations occurred}.  
     
\begin{table}[p]
    \begin{center}
        \renewcommand{\arraystretch}{1.25}
        \begin{tabular}{|c|c|c|c|c|}
            \hline
            \multirow{2}{*}{Experiment} & \multicolumn{2}{|c|}{$Ns_1$} & \multicolumn{2}{|c|}{$Ns_2$} \\ \cline{2-5}
                                                       & $\Delta_m$&\textsf{Aramis} & $\Delta_m$&\textsf{Aramis} \\ \hline \hline
            1 & 240 & 10544, (0) & 212 & 10544, (1) \\ \hline
            2 & 553 & 6874, (0) & 527 & 6874, (0) \\ \hline
            3 & 517 & 17452, (0) & 402 & 17452, (0) \\ \hline
            4 & 334 & 18487, (0) & 274 & 18483, (0) \\ \hline
            5 & 426 & 12483, (0) & 322 & 12483, (1) \\ \hline
            6 & 717 & 4723, (0) & 429 & 4723, (0) \\ \hline
            7 & 491 & 8936, (0) & 816 & 8936, (0) \\ \hline
            8 & 510 & 393, (0) & 475 & 392, (0) \\ \hline
            9 & 478 & 3798, (0) & 931 & 3798, (0) \\ \hline
            10 & 234 & 17341, (0) & 290 & 17805, (0) \\  \hline \hline
            $R_{ex}$ & \multicolumn{2}{|c|}{1} & \multicolumn{2}{|c|}{0.9999803} \\ \hline
        \end{tabular}
        \caption[\textsf{Aramis} deliveries before GMS detects node crash ($R=0.9999$, $\rho_{min}=1$)]{\textsf{Aramis} deliveries (Order Violations) before GMS detects $Ns_3$ has crashed \\ $R=0.9999$, $\rho_{min}=1$}
        \label{table:crashed_node_rho1}
    \end{center}
\end{table}

\begin{table}[p]
    \begin{center}
        \renewcommand{\arraystretch}{1.25}
        \begin{tabular}{|c|c|c|c|c|}
            \hline
            \multirow{2}{*}{Experiment} & \multicolumn{2}{|c|}{$Ns_1$} & \multicolumn{2}{|c|}{$Ns_2$} \\ \cline{2-5}
                                                       & $\Delta_m$&\textsf{Aramis} & $\Delta_m$&\textsf{Aramis} \\ \hline \hline
            1 & 664 & 5509, (0) & 580 & 5509, (0) \\ \hline
            2 & 636 & 13697, (0) & 555 & 13697, (0) \\ \hline
            3 & 1020 & 2688, (0) & 496 & 2688, (0) \\ \hline
            4 & 320 & 19481, (0) & 279 & 19485, (1) \\ \hline
            5 & 331 & 19012, (0) & 400 & 19106, (0) \\ \hline
            6 & 456 & 2669, (0) & 466 & 2669, (0) \\ \hline
            7 & 432 & 10823, (0) & 939 & 10823, (0) \\ \hline
            8 & 271 & 18412, (0) & 272 & 18414, (0) \\ \hline
            9 & 498 & 5440, (0) & 362 & 5449, (0) \\ \hline
            10 & 716 & 3611, (0) & 376 & 3611, (0) \\ \hline \hline
            $R_{ex}$ & \multicolumn{2}{|c|}{1} & \multicolumn{2}{|c|}{0.9999901} \\ \hline
        \end{tabular}
        \caption[\textsf{Aramis} deliveries before GMS detects node crash ($R=0.9999$, $\rho_{min}=2$)]{\textsf{Aramis} deliveries (Order Violations) before GMS detects $Ns_3$ has crashed \\ $R=0.9999$, $\rho_{min}=2$}
        \label{table:crashed_node_rho2}
    \end{center}
\end{table}

\begin{table}[p]
    \begin{center}
        \renewcommand{\arraystretch}{1.25}
        \begin{tabular}{|c|c|c|c|c|}
            \hline
            \multirow{2}{*}{Experiment} & \multicolumn{2}{|c|}{$Ns_1$} & \multicolumn{2}{|c|}{$Ns_2$} \\ \cline{2-5}
                                                       & $\Delta_m$&\textsf{Aramis} & $\Delta_m$&\textsf{Aramis} \\ \hline \hline
            1 & 452 & 17651, (0) & 451 & 21064, (0) \\ \hline
            2 & 475 & $-$ & 679 & - \\ \hline
            3 & 754 & 3911, (0) & 515 & 3911, (0)  \\ \hline
            4 & 355 & 16516, (0) & 515 & 3911, (0)  \\ \hline
            5 & 214 & 17620, (0) & 503 & 17619, (0)  \\ \hline
            6 & 386 & 12968, (0) & 694 & 12968, (0)  \\ \hline
            7 & 453 & 7311, (0) & 345 & 7311, (0)  \\ \hline
            8 & 632 & 12613, (0) & 546 & 12613, (0)  \\ \hline
            9 & 356 & 18030, (0) & 569 & 18034, (0)  \\ \hline
            10 & 695 & 13907, (0) & 511 & 13907, (0)  \\ \hline \hline
            $R_{ex}$ & \multicolumn{2}{|c|}{1} & \multicolumn{2}{|c|}{1} \\ \hline

        \end{tabular}
        \caption[\textsf{Aramis} deliveries before GMS detects node crash ($R=0.9999$, $\rho_{min}=3$)]{\textsf{Aramis} deliveries (Order Violations) before GMS detects $Ns_3$ has crashed \\ $R=0.9999$, $\rho_{min}=3$}
        \label{table:crashed_node_rho3}
    \end{center}
\end{table}

\begin{table}[p]
    \begin{center}
        \renewcommand{\arraystretch}{1.25}
        \begin{tabular}{|c|c|c|c|c|}
            \hline
            \multirow{2}{*}{Experiment} & \multicolumn{2}{|c|}{$Ns_1$} & \multicolumn{2}{|c|}{$Ns_2$} \\ \cline{2-5}
                                                       & $\Delta_m$&\textsf{Aramis} & $\Delta_m$&\textsf{Aramis} \\ \hline \hline
            1 & 387 & 17982, (0) & 453 & 17016, (1)  \\ \hline
            2 & 7507 & 255, (0) & 3804 & 742, (0)  \\ \hline
            3 & 2019 & 8117, (0) & 1676 & 8117, (0)  \\ \hline
            4 & 3094 & - & 1899 & -  \\ \hline
            5 & 264 & 10876, (0) & 416 & 10880, (0)  \\ \hline
            6 & 683 & 9262, (0) & 605 & 9262, (0)  \\ \hline
            7 & 244 & 18224, (0) & 301 & 18222, (0)  \\ \hline
            8 & 1160 & 2207, (0) & 830 & 2207, (0)  \\ \hline
            9 & 334 & 19058, (0) & 278 & 19060, (0)  \\ \hline
            10 & 233 & 17588, (0) & 421 & 17586, (0)  \\ \hline \hline
            $R_{ex}$ & \multicolumn{2}{|c|}{1} & \multicolumn{2}{|c|}{0.9999903} \\ \hline

        \end{tabular}
        \caption[\textsf{Aramis} deliveries before GMS detects node crash ($R=0.99999$, $\rho_{min}=1$)]{\textsf{Aramis} deliveries (Order Violations) before GMS detects $Ns_3$ has crashed \\ $R=0.99999$, $\rho_{min}=1$}
        \label{table:crashed_node_R.99999}
    \end{center}
\end{table}

    \subsection{Evaluation}
    From Tables \ref{table:crashed_node_rho1}, \ref{table:crashed_node_rho2},  \ref{table:crashed_node_rho3} and \ref{table:crashed_node_R.99999} we can clearly see that the \textsf{ABcast} protocol allows for a large number of \emph{abcast}s to be delivered in the interim period between a node crashing and the GMS protocol detecting it.  With an individual node delivering, on average, greater than $10^4$ \emph{abcast}s and in one case more than double that amount.  Furthermore, out of $40$ experiments there was only two instances where there was no benefit to using the \textsf{ABcast} protocol, and this was when the protocol utilised more conservative values of $R=0.9999$ or $\rho_{min}=3$.  
    
    In \ref{table:crashed_node_summary}, we can clearly see that increasing the size of $\rho_{min}$ has a direct impact on the reliability of \textsf{Aramis}, as the number of order violations reaches zero when $\rho_{min}$ is at its largest.  This can be explained by a larger $\rho_{min}$ increasing the calculated $\Delta_m$ value for each \emph{abcast} (as seen in Tables \ref{table:crashed_node_rho1}, \ref{table:crashed_node_rho2},  \ref{table:crashed_node_rho3}) \footnote{The difference in calculated $\Delta_m$ values is not significant between $\rho_{min}=1,2,3$ in our results, however this can be attributed to the varying state of the underlying network.  Our experiments were conducted in sets based upon their constant values, e.g. all ten experiments that utilised $\rho_{min}=1$ and $R=0.9999$ were performed one after the other.  Therefore, as these experiments take several minutes each, the time required to conduct all of the experiments was significant, and as a consequence these experiments were conducted over several days.  Consequently, the load on the underlying network will have varied for each set of experiments.  However, we can still attribute the reduced number of order violations to an increase in $\Delta_m$, as this variable is calculated based upon latencies that represent the networks current state.  Therefore, if a smaller $\rho_{min}$ value was utilised under the exact same network conditions as the $\rho_{min}=3$ experiments, we know that the calculated $\Delta_m$ value would have been significantly smaller.}.  
    
    Conversely, when we increase $R$ from $0.9999$ to $0.99999$, with $\rho_{min} = 1$, the number of violations is reduced from two to one, at the expense of a greatly enlarged $\Delta_m$ (compared to $\rho_{min}=1,2,3$ when $R=0.9999$).  
    
    From its initial conception, \textsf{ABcast} has been designed with pessimistic assumptions in order to minimise the chances of $\Delta_m$ being exceeded by a given \emph{abcast}.  This pessimism is reflected in our experiments, with Tables (\ref{table:crashed_node_rho1}, \ref{table:crashed_node_rho2},  \ref{table:crashed_node_rho3}, \ref{table:crashed_node_R.99999}) all showing that the experienced $R$, denoted as $R_{ex}$, is greater than the user specified $R$.  Where $R_{ex}$ for a given set of experiments is calculated as
    
    \begin{equation}\label{eq:afc_mu_norm}
		     \begin{aligned}
		         1 - R_{ex} = \frac{\sum\limits_{1}^{10} \quad \text{ Number of Order Violations}}{\sum\limits_{1}^{10} \quad \text{ Messages Delivered by Aramis}}
		     \end{aligned}
    \end{equation}
    
    \noindent unless the number of messages delivered by \textsf{Aramis} is zero, in which case $R_{ex} = 1$.  
    
    Finally, while our experiments show that a larger number of \emph{abcast}s are delivered in the interim period between node failures and detection, we believe that in the event of a \textquoteleft{}real' crash this value could be much higher.  In our experiments we crash the JVM instantly, which results in the TCP sockets utilised by the \texttt{FD\_SOCK} protocol being closed immediately.  This means that it is almost certainly the \texttt{FD\_SOCK} protocol that detects the failure of $Ns_3$ each time.  If a crash was preceded by a slowing down period where node responses become more staggered and the node was unresponsive, but still running and maintaining an open TCP socket, it is highly probable that the total number of \emph{abcast}s sent in the interim period would be much larger, as the alternative failure detection protocol \texttt{FD\_ALL} has a default timeout period of $40$ seconds.  
        
    \subsection{Summary}
        We have found that utilising the \textsf{ABcast} protocol for \emph{abcast}s allows for a significant number of messages ($> 10^4$) to be delivered in the interim period between a node crash and the GM protocol publishing a new view.  Furthermore, we have found that increasing both $\rho_{min}$ and $R$ reduces the chances of order violations occurring in the presence of node crashes.  When $\rho_{min} = 1$, $R_{ex}$ is much larger than the specified $R$, with the difference increasing as $\rho_{min}$ becomes larger.  However, a larger $\rho_{min}$ can occasionally risk \textsf{Aramis} not being able to deliver any \emph{abcast}s before the GM publishes a new view, so it is recommended to keep $\rho_{min}=1$.  
          
\section{Summary}
In this chapter, we have presented a thorough performance evaluation of both the \textsf{AmaaS} model and the \textsf{ABcast} protocol.  We have shown that, as the number of nodes involved in a transaction increases, the \textsf{AmaaS} model, coupled with the \textsf{SCast} protocol, can improve the average latency and throughput of distributed transactions when compared to the existing P2P approach.  

Additionally, we have shown that the \textsf{ABcast} protocol can provide comparable performance to existing deterministic protocols, such as TOA, when utilised within a \textsf{AmaaS} service.  Crucially, this performance does not come at the expense of \textsf{ABcast}'s guarantees, as we have demonstrated that these guarantees can be met when handling large numbers of \emph{abcast}s.  Furthermore, we have shown that with the correct configuration parameters, it is possible to avoid order violations when node crashes occur.  Finally, we have shown that \textsf{ABcast}'s non-blocking message delivery enables a significant number of \emph{abcast} messages to be delivered in the interim period between a node crashing and a GM protocol detecting it.  