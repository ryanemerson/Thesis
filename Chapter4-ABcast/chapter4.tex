\chapter{ABcast}

% **************************** Define Graphics Path **************************
    \graphicspath{{Chapter4-ABcast/Figs/Vector/}{Chapter4-ABcast/Figs/}}

In this chapter we  introduce a hybrid \emph{abcast} protocol, called \textsf{ABcast}, which provides non-blocking message delivery in the presence of node failures and low-latency message delivery in their absence.  This protocol was designed for use within the \textsf{AmaaS} system model, however the protocol can also be utilised in other environments where non-blocking \emph{abcast}s are required between a small number of nodes.  

First we introduce the rational behind utilising a Hybrid protocol and our design approach for \textsf{ABcast}, before detailing the protocol's requirements and assumptions.  This is followed by an in-depth look at the components required by \textsf{ABcast}, and how they have been implemented.  We then explore the two protocols used to create the hybrid solution in detail, outlining each protocols delivery and rejection criteria for \emph{abcast} messages in order to understand how the two individual protocols co-exist to create a low-latency non-blocking hybrid \emph{abcast} protocol.  Finally we discuss the limitations of the protocol's current design and the need for a bespoke flow control algorithm for use with \textsf{ABcast}.  

\section{Rational and Design Approach}
    In the previous chapter we introduce \textsf{AmaaS}, a new system model that aims to increase the transactional throughput of distributed in-memory transactional systems.  This model depends on a \emph{abcast} protocol to maintain a replicated state between the service nodes which provide multicast ordering to client nodes; where each multicast request requires a state change between service nodes.  For such a service to be viable it is vital that it provides low-latency responses to the requesting client nodes and can handle an increasing number of client requests as a the transactional system scales.  Furthermore it is essential that such a service maintains high-availability, even in the presence of node failures, as an entire cluster of client nodes are dependent on the service.  Therefore, is essential that the underlying \emph{abcast} protocol utilised by the service can provide both non-blocking and low-latency message delivery, to satisfy the clients requirements of highly-available and low-latency requests respectively.  
    
    The FLP impossibility\citep{Fischer:1985:IDC:3149.214121} dictates that in an asynchronous environment \emph{abcast} protocols must either admit blocking to meet its atomic guarantees or permit a likelihood of its guarantees not being met.  As  previously stated, known blocking protocols are of two types: GM dependent and Quorum based, both of which admit blocking in order to remain atomic.  The quorum based protocols block mildly due to false/valid suspicions of the leader node and GM protocols block severely but only in the presence of node failures.  Quorum based protocols provide non-blocking message delivery, however they only provide low levels of throughput as they are typically leader based, which will ultimately limit the scalability of the transactional system.  Furthermore, it is also possible (although unlikely in practice) that such protocols can become stuck indefinitely in a cycle of leader elections after the previous leader node has crashed, or is falsely suspected of crashing.    On the contrary GM based protocols provide very low latency \emph{abcast}'s that can handle high levels of throughput, however the severe blocking inherent in GM protocols would critically undermine an \textsf{AmaaS} service's availability in the event of a service node crash.  
    
    From the disadvantages stated above, it is clear that protocols belonging to the blocking category of protocols are not best suited for use within \textsf{AmaaS}.  Therefore it is necessary for us to adopt the alternative approach and allow for the possibility that the atomic guarantees G1-G4 ($\S$ \ref{ssec:atomic_broadcast}) will not always be met.  Utilising probabilistic guarantees on message delivery is an established technique for increasing the scalability of network multicasting systems\citep{Kermarrec:2003:PRD:766617.766623}, and it is has also been applied to \emph{abcast} protocols.  
    
    Felber \emph{et al.} \citep{Felber01probabilisticatomic} propose an \emph{abcast} protocol, \textsf{PABCast}, that provides probabilistic guarantees on both message \emph{safety} and \emph{liveness}.  If these probabilistic guarantees are not met, then it is possible for only a subset of the destination set to receive a broadcast, or for all destinations to deliver the broadcast but in an inconsistent ordering.  The aim of the  \textsf{PABCast} protocol is to provide increased scalability for atomic broadcasts across large numbers of destinations, not a small subset of nodes as required by the \textsf{AmaaS}.  As such the protocol does not consider throughput a primary concern.  This is evident in the protocols use of \emph{rounds} to regulate when a node can initiate a broadcast; a node cannot initiate a new broadcast until all broadcasts sent by the cluster in the current round have been delivered by the local node.  Ultimately this limits the sending node to a single broadcast at a time, which will clearly limit the protocol's throughput capabilities.  In the literature the performance of \textsf{PABCast} is evaluated using a simulation that focuses on the scalability of the system in terms of message cost as well as the likelihood of a broadcast's \emph{safety} and \emph{liveness} being violated due to the probabilistic guarantees not being met. The performance evaluation presented in the paper does not consider the throughput or latency of the \textsf{PABCast} protocol, and the protocol is only evaluated in a simulation so it is not possible to ascertain how such a protocol will function in an actual asynchronous system.  Ultimately \textsf{PABCast} is not suitable for use in the \emph{AmaaS} system model.  
    
    Our approach is to combine a deterministic and probabilistic \emph{abcast} protocol in order to create a hybrid protocol that can provide high-throughput, low-latency message delivery when node failures are absent, whilst providing non-blocking message delivery when node failures do occur or are suspected.  This hybrid protocol consists of the probabilistic protocol \textsf{Aramis} and the deterministic protocol \textsf{Base} which are combined to create the \textsf{Aramis} and \textsf{Base} Atomic Broadcast protocol - \textsf{ABcast}.  
    
    \textsf{Aramis} is a non-blocking \emph{abcast} protocol that guarantees G1, G2 and G4 with a probability close to 1; G3 is deterministic and will always hold.  It utilises the probabilistic synchronous model ($\S$ \ref{ssec:probabilistically_synchronous}), in conjunction with synchronised clocks, to calculate a probabilistic upper bound on \emph{abcast} delivery times; we refer to this upper bound as a message's delivery delay, $\Delta_m$.  Upon receiving an \emph{abcast} message, a destination node waits for the calculated delivery delay to expire before delivering the message to the application.  If a message $m$ does not reach its destination, $d$, before its delivery time, then it is possible for a subsequent message $m'$ to be delivered ahead of $m$ in the total order if $\Delta_m'$ expires before $m$ is received by $d$.  When such a scenario occurs the \emph{abcast} guarantees G1 and G4 will not be met and therefore the broadcast cannot be considered to be atomic.  Furthermore, it is necessary for $d$ to reject $m$ in order to prevent $m$ from knowingly been delivered in the wrong place in the total order; hence guarantee G2 is also not met.  
    
    A key advantage of the \textsf{Aramis} approach is that no message acknowledgements are required for a message to be delivered, instead it depends entirely on the calculated delivery delay.  Relying solely on this delay ensures that faulty nodes have no effect on the delivery of a message at correct nodes and it is therefore impossible for a message's delivery to become blocked.  Furthermore, as no quorums or acknowledgements are required, it is possible for  \textsf{Aramis} to tolerate at most $(n - 1)$ crashes when $n$ nodes are involved in a broadcast.  
    
    The \textsf{Aramis} protocol was developed to be risk adverse, with all probabilistic calculations designed pessimistically in order to ensure that the delivery delay is rarely exceeded by an \emph{abcast} message.  Furthermore, the delivery delay must always assume the worst case scenario will happen when the protocol is executing (e.g. the originator node crashing during broadcast) to ensure that such situations are catered for.  A consequence of this pessimism, is that the \emph{broadcast-to-delivery} latency of a \emph{abcast} message can be very large, typically 100-1000ms.  These large latencies are not appropriate for use in many systems, and especially not the \textsf{AmaaS} model, therefore the \textsf{Aramis} protocol alone is not sufficient for providing the low-latency, non-blocking \emph{abcast} messages required by \textsf{AmaaS}.  
    
    To counteract the large delivery latencies associated with the \textsf{Aramis} protocol, we decided that it was necessary for a second \emph{abcast} protocol, \textsf{Base}, to be utilised alongside \textsf{Aramis}.  The \textsf{Base} protocol is a GM based deterministic protocol, similar to NewTop\citep{Ezhilchelvan:1995:NFG:876885.880005}, that provides low-latency high throughput \emph{abcast}s at the expense of blocking when node failures occur. The protocol is acknowledgement based and consists of two phases: First the message's originator, $m.o$ broadcasts $m$ to all $d \in m.dst$; Secondly, all $d' \in m.dst - \{m.o\}$ send an acknowledgement, $ack(_{d'})$  to each $d \in m.dst$ whom upon receiving all of the acks can deliver $m$.  If a single $d \in m.dst$ crashes during the \emph{abcast},  then it is possible that some of the required acks will never arrive at all destinations, in which case message delivery is blocked until the GM service detects the crash and appropriate action is taken by the protocol.  
    
    In order to hone the advantages of both protocols it was necessary to create the hybrid protocol \textsf{ABcast}.  This protocol is created by utilising the delivery conditions of the \textsf{Base} protocol when no node failures are present, and utilising those of \textsf{Aramis} when a broadcast message has not been delivered by \textsf{Base} after $\Delta_m$ has expired.  This approach provides the application with the low-latency of \textsf{Base} for the majority of message deliveries, whilst ensuring that a message will not wait on a acknowledgement for more than $\Delta_m$.  In the event of a node failure the \textsf{Base} protocol does not have to wait for the GM service to detect a crash before message delivery becomes unblocked.  Instead, messages will be delivered by \textsf{Aramis} after $\Delta_m$ expires.  Therefore, when node failures are present the \textsf{ABcast} protocol will always allow for a greater throughput of delivered messages than a traditional GM based protocol, as long as $\Delta_m$ remains smaller than the time it takes the GM to detect a node failure.  In the worse case, if the GM delay is smaller than $\Delta_m$, than the \textsf{Base} protocol can simply unblock its message buffer and continue to delivery messages without the use of \textsf{Aramis}.  Finally, in normal working conditions, the \textsf{ABcast} protocol should have similar performance to a traditional GM based protocol as, in the majority of cases, \textsf{Aramis} is not used for message delivery.  

As the \textsf{ABcast} protocol utilises the probabilistic protocol \textsf{Aramis}, it is possible for a node to miss a message in the total order if \textsf{Aramis} takes over message delivery.  However, as previously stated, in practice the probability of \textsf{Aramis} meeting its guarantees is close to 1.  Furthermore, as \textsf{Aramis} is only used when \textsf{Base} is slow or a node failures occurs, the probability of an \emph{abcast} message $m$ being missed in the total order is the product of two very small probabilities; \textsf{Base} not being able to deliver $m$ and \textsf{Aramis} failing $m$.  Therefore, in reality the occurrence of message miss-orderings is rare.  

In this section we have described the inspiration and rational behind the \textsf{ABcast} protocol, as well as presenting some high-level details of how the hybrid protocol functions.  In the next section we present the underlying assumptions made when designing \textsf{ABcast}, before detailing the specific components required to implement the protocol.  Lastly, we take in-depth look at both the \textsf{Aramis} and \textsf{Base} protocols, detailing the specifics of the each protocols delivery conditions as well as the maths behind the probabilistic guarantees.  

\newpage
\section{Assumptions}
	This section first defines the four key assumptions made when designing the \textsf{Aramis} protocol.  Before exploring each assumption in detail, explaining the rational behind each assumption as well as exploring the technologies required to ensure each assumption held.  

	\paragraph{Assumptions:}\hspace{0pt} \\
	\begin{description}	
	% ******** Is this the case? Why?
		\item [\textbf{A1 - Fault Tolerance}] \hfill \\
		At most ($n-1$) of $n$ nodes involved in a broadcast can crash. However, 2 or more nodes cannot crash within an interval of some finite duration $D$ that is smaller than a few seconds.
		
        \item [\textbf{A2 - Synchronised Clocks}] \hfill \\
		At any moment, clocks of any two operative nodes participating in a \textsf{ABcast} are synchronised.  
		
		We meet \textbf{A2} by implementing the well known clock synchronisation algorithm \citep{Cristian:1996:SA:227210.227231}.  The details of our implementation and the parameters used are explored in $\S$ \ref{ssec:clocksynch}.		
		
		\item [\textbf{A3 - Reliable Communication}] \hfill \\
		When an operative node broadcasts $m$ to all $m.dst$, all operative destinations $d \in m.dst$ will eventually receive $m$.  
		
		We use reliable UDP protocol to guarantee that all operative nodes receive $m$ in crash-free scenarios.  However, when crashes occur, the use of reliable UDP alone is not enough to ensure that all of the operative destinations receive $m$.  Therefore, a reliable broadcast, \emph{rbcast}, protocol is required to ensure \textbf{A3}.  The Reliable UDP and \emph{rbcast} protocol we use are explored in detail in $\S$ \ref{ssec:reliable_udp} and $\S$ \ref{ssec:rbcast}, respectively.  
		
		\item [\textbf{A4 - Probabilistically Synchronous}] \hfill \\
        Let random variable $x$ denote the message communication delay between any pair of operative nodes. The maximum delay, $x_{mx}$, estimated by observing $NT_P$ number of transmissions from the recent past, will \emph{not} be exceeded during $NT_F$ number of future transmissions that unfold next, where $NT_F \leq NT_P$ with a high probability ($1 - q$).
		
    	\textbf{A4} is motivated by previous research conducted by Ezhilchelvan \emph{et al.} \citep{Ezhilchelvan:2010:LPR:1773912.1773927} into PSM, which proposes that the challenges of designing asynchronous distributed systems, namely the FLP impossibility, can be avoided by assuming that the underlying network communication is synchronous to a given probability.  This assumption is a foundation of the \textsf{ABcast} protocol and its ability to provide non-blocking \emph{abcast}, as the variable $x$ is utilised by the \textsf{Aramis} protocol to place an upper bound on the delivery delay of each \emph{abcast} message.  The measurement of $x$, $x_{mx}$ and $q$, as well as past experiments used to validate \textbf{A4}, are presented in $\S$ \ref{ssec:dmc}.  	
    	
    	A consequence of this assumption, is that \textsf{ABcast} can only be utilised in data centres and cluster-based environments.  It is not suitable for use over the Internet, or similar networks that are susceptible to large fluctuations in network delays over a short period of time.  This is because frequent fluctuations in network delays would consistently undermine the assumptions of PSM.  
	\end{description}
	
\section{ABcast Components}
In this section we detail the individual components required by the \textsf{ABcast} protocol.  For each component, we explain its purpose and design; with important implementation details highlighted where appropriate.  All of the protocols presented in this thesis are implemented in Java using the JGroups \citep{JGroups} network framework.  

    \begin{figure}[!h] 
        \centering    
         \includegraphics[width=0.8\textwidth]{components_no_fcc}
         \caption[\textsf{ABcast} Protocol Components Overview]{\textsf{ABcast} Protocol Components}
         \label{fig:abcast_components}
    \end{figure}
    
   Figure \ref{fig:abcast_components} provides an overview of all of the components required by the \textsf{ABcast} protocol; where GM is the Group Membership service provided by JGroups, DMC is the Delay Measurement Component (\ref{ssec:dmc}) and \emph{rbcast} is the Reliable broadcast Component (\ref{ssec:rbcast}).  

	\subsection{Clock Synchronisation}\label{ssec:clocksynch}
	In order to provide synchronised clocks between nodes executing \textsf{ABcast}, we implemented the probabilistic clock synchronisation algorithm presented in \citep{Cristian:1996:SA:227210.227231} as a dedicated protocol in JGroups.  Cristain's algorithm is a master/slave protocol, that utilises a single master whose local clock time is applied to all slaves; with each slave periodically issuing a clock synchronisation request to the master in order to synchronise their clocks.  
			
			At any moment, a slaves clock value is synchronised with the master node with a maximum error rate of $\epsilon$, with probability $\mathcal{P}_\epsilon \geq (1- 10^{-5})$. All of the experiments presented in this thesis utilise clock synchronisation with $\epsilon$ estimated as $1$ millisecond (ms).  A major consideration when estimating $\epsilon$ is the worst-case rate of clock drift between successive synchronisations. Ultimately, the longer the synchronisation interval, the larger the drift rate between clocks.  Estimation of $\epsilon = 1$ usually assumes an interval of $45$ minutes between synchronisations, however we use a shorter $15$ minute interval in order to increase $\mathcal{P}_\epsilon$.
			
			As each slave node synchronises its clock value with that of the master, it is possible for any two slave nodes to have a maximum error rate of $2\epsilon$.  This is because a slave $N_i$ could synchronise its clock behind the master's clock value by $\epsilon$ time.  Whereas, another slave $N_j$ could synchronise its clock ahead of the master by $\epsilon$. Hence, it is possible that $N_j.clockValue - N_i.clockValue = 2\epsilon$.  

    \subsection{Group Membership}\label{ssec:jgroups_gm}
	JGroups provides a GM service, called GMS which simply stands for Group Membership Service. GMS works as follows: upon discovering that a new node has joined the group or a node failure has occurred, GMS issues a new view to all of the protocols in the JGroups stack.  It is then the responsibility of the individual protocols to take the appropriate action when a new view is issued.  For example, unblocking message delivery if the local node was waiting for an acknowledgement from a node that is no longer present in the newly issued view.  	
	
	\subsection{Reliable UDP}\label{ssec:reliable_udp}
	JGroups provides a reliable UDP protocol, \textsf{UNICAST3}, which guarantees that all UDP messages sent by a protocol higher in the network stack arrive at their destinations when node crashes do not occur.  This reliable UDP layer is placed below \textsf{ABcast} in the network stack to ensure that when messages are broadcast they are received by all destinations; where a broadcast consists of $m$ being unicast via \textsf{UNICAST3} to each of its intended recipients.  
	
	As well as providing reliable UDP unicasts, the \textsf{UNICAST3} protocol provides \emph{node-to-node} ordering as default for each message sent.  This ordering means that if a node $N_i$ sends two consecutive unicast messages, $m_1$ followed by $m_2$, to $N_j$, then $N_j$ will not deliver $m_2$ until it has first delivered $m_1$.  This behaviour is not always appropriate, therefore \textsf{UNICAST3} allows for messages to be sent Out Of Band (OOB), which simply means that messages will be sent reliably but they will be delivered at a destination as soon as they are received, regardless of the messages that have (or have not) been delivered before it.  
	
	\subsection{Reliable Broadcast}\label{ssec:rbcast}
    In the event of a node failure Reliable UDP alone is not sufficient to ensure that assumption A3 holds.  This is because its possible for a messages originator, $m.o$, to crash during the unicasting of $m$.  Assume that $m.dst = \{N_i, N_j, N_k\}$ and $m.o = N_i$, if $N_i$ crashes after unicasting $m$ to $N_j$ then $N_k$ will never receive $m$.  Similarly, if $N_i$ crashes during the unicasting of $m$ to $N_j$ it is possible that $N_i$ managed to send $m$ at least once, in which case it may eventually be received.  Both scenarios highlight that an additional protocol is required to ensure that all $m.dst$ receive $m$ in the event of node failures.  
    
    To overcome the limitations of Reliable UDP we have implemented a Reliable Broadcast protocol, based upon the work by  Ezhilchelvan \emph{et al.} \citep{ezhilchelvan2011near}, that we call \emph{rbcast}, which utilises redundant broadcasts to ensure all destinations receive a broadcast.  \emph{Rbcast} has been designed specifically for use with PSM based protocols and consequently utilises some of the values from the DMC ($\S$ \ref{ssec:dmc}) as protocol parameters.  Utilising the values provided by DMC allows  \emph{rbcast} to place a probabilistic timeliness guarantee on each message that is reliable broadcast.  This means that, with a high probability, \emph{rbcast} can guarantee that an operative destination will receive a given $m$ within $D$ time, even if $m.o$ crashes during the initial broadcast of $m$.  The remainder of this section describes the basic \emph{rbcast} protocol, before describing how $D$ is calculated.
    
    \subsubsection*{\emph{rbcast} protocol}
    As previously stated, the \emph{rbcast} protocol utilises redundant broadcasts to ensure that all $d \in m.dst$ receive $m$.  With each broadcasting node, called the message originator $m.o$ ($m.o = N_i$), broadcasting ($\rho + 1$) copies of $m$; where $\rho$ is a redundancy estimate provided by the DMC.  Redundant copies of $m$ are identical to the original broadcast, except for the field $m.copy$ which identifies the current copy of $m$ being broadcast - $m.copy = 0,\ldots,\rho$.  Successive broadcasts of $m$ are made $\eta$ time apart to ensure that subsequent copies of $m$ do not effect the transmission delay of the preceding broadcast, which is vital for the DMC to accurately calculate the variables required by \emph{Aramis} and \emph{rbcast}.  Furthermore, the use of $\eta$ ensures that multiple copies of $m$ are not bundled into the same UDP packet by the underlying transmission protocol.\footnote{Bundling can simply be disabled for subsequent copies of $m$, however this would prevent $m.copy > 0$ from being bundled with future broadcasts $m'.copy = 0$, hence some performance benefits gains would be lost.}  Finally, in addition to the $m.copy$ field, each $m$ includes the values $m.\rho$ and $m.\eta$ both of which are calculated by $m.o$'s local DMC.  
    
    A \emph{rbcast} of $m$ is considered a success if every operative $d \in m.dst$ receives at least one copy of $m$.  Any destination $N_j$ that receives $m.copy = k < \rho$ cooperates to ensure this success.  A destination waits to receive $m.copy \geq k + 1$ within a timeout $\eta + \omega$, where $\eta= m.\eta$ and $\omega$ is $N_i$'s estimate of the network's Packet Delay Variation (PDV); $\omega$ is also included in $m$ as $m.\omega$.  If the timeout expires, $N_j$ assumes that $N_i$ has crashed while broadcasting $m.copy = k$ and starts broadcasting $m.copy = k, k+1,\ldots, \rho$ on behalf of $N_i$. To reduce the possibility that no one else is acting on behalf of $N_i$, $N_j$ adds a further random wait, $\zeta$, which is uniformly distributed on ($0,\eta$), before broadcasting $m.copy = k+1$.  This process continues until all $d \in m.dst$ have received or broadcast $m$ with $m.copy = \rho$.  
    
    Note that if $N_i$ does not crash, or if it crashes and an operative $s$-node receives $m$, then $m$ is broadcast \emph{at least} ($\rho + 1$) times.  Conversely, if $N_i$ crashes during the initial broadcast of $m$, and no members of $m.dst - \{m.o\}$ receive a copy of $m$, then the broadcast has failed and $m$ is lost.  This is acceptable for \textsf{ABcast}, because if no $d \in m.dst - \{m.o\}$ receive $m$, then its not possible for an inconsistent total order of messages to occur between participants of an \emph{abcast}.  
    
%    The significance of $\eta, \rho$ and $\omega$ are discussed in detail in $\S$ \ref{ssec:dmc}.  
    
	\subsection{Delay Measurement Component}\label{ssec:dmc}
        For the sake of clarity, assumption A4 is repeated below:	
        
        \begin{quotation}
            The maximum delay, $x_{mx}$, estimated by observing $NT_P$ number of transmissions from the recent past, will \emph{not} be exceeded during $NT_F$ number of future transmissions that unfold next, where $NT_F \leq NT_P$ with a high probability ($1 - q$).
        \end{quotation}
	
        The delay measurement component is responsible for monitoring and observing the network latency of $NT_P$ transmissions from the recent past.  This recent past of latencies is then used to calculate various parameters that are required by the \emph{rbcast} and \textsf{ABcast} protocols for executing \emph{abcasts} in the near future.  Being conservative, we use $NT_F = 10\%$ of $NT_P$ and $NT_P=1000$; so, a \textsf{ABcast} node freshly estimates $x_{mx}$ for every 100 new delays it observes.  Each fresh estimation of $x_{mx}$ results in the recalculation of the following parameters: $\eta, \rho, q$ and $\omega$.  
        
        Latencies are measured by the DMC based upon the timestamp $m.ts$, which is included in every message $m$ that is broadcast via the \emph{rbcast} protocol.  As the clocks of all nodes executing the \textsf{ABcast} protocol are synchronised, it is possible to measure the one-way latency of each message that is received by a node.  A node $N_i$ sends an \emph{rbcast} $m$ to $N_j$, upon receiving $m$, $N_j$ immediately records the latency $x$:

        \begin{equation*}
		     \begin{aligned}
		         x = (N_j.clockValue - m.ts) + 2\epsilon
		     \end{aligned}
        \end{equation*}        
        
        It is necessary to add $2\epsilon$ to each latency to ensure that if $N_j.clockValue$ is behind $N_i.clockValue$ by the maximum error of $2\epsilon$, a positive latency value is still recorded; this assumes that neither $N_i$ or $N_j$ is the clock master, in which case it is not possible for the max clock difference to be $2\epsilon$, only $\epsilon$, however the \emph{rbcast} is independent of the clock synch algorithm used and so $2\epsilon$ is pessimistically added to all latencies.  
                
        The remainder of this section explores each of the parameters provided by the DMC, explaining what they represent and how they are calculated.  
        
        \begin{description}
        \item[\Huge$\boldsymbol{x_{mx}}$] \hfill \\
        $x_{mx}$ is simply the largest latency out of the $NT_P$ latencies observed in the recent past.  
        
        \item[\Huge$\boldsymbol{q}$] \hfill \\
                The parameter $q$ is the estimated probability that a transmission delay observed in the near future will exceed $x_{mx}$.  We estimate $q$ by observing the ratio of observed delays from the recent past that exceed $95\%$ of the recorded $x_{mx}$; thus, when more delays are observed closer to $x_{mx}$, $q$ tends to be large.  Although unlikely, it is possible that $q$ can be calculated as $1$ if all latencies in the recent past are the same, to avoid this we set a maximum value for $q$, $ q \leq q_{mx}$.  $q_{mx}$ is calculated as: 

        \begin{equation*}
		     \begin{aligned}
		          q_{mx} = \sqrt{1 - R^{(\frac{1}{n} - 1)}}
		     \end{aligned}
        \end{equation*}
        
        Where $R$ is a constant defined before run-time that specifies to what probability the system will be \emph{reliable}, as the system is probabilistic the following must be true $R < 1$.  Note that $q$ cannot be accurately estimated, as it relates to future delays.  Therefore, \textsf{ABcast} uses $q$ estimates in a manner that accounts for potential inaccuracies and only for estimating one other parameter - $\rho$.
	
	    \item[\Huge$\boldsymbol{\rho}$] \hfill \\
	    $\rho$ is the parameter that determines the number of redundant broadcasts that are sent by the \emph{rbcast} protocol.  As \emph{rbcast} sends ($\rho + 1$) broadcasts, $rho = 1$ is sufficient for crash-tolerance, however we estimate it so that at least one copy of $m$ reaches all operative nodes other than $m.o$ within $x_{mx}$ delay and with a probability $> R$; more precisely, $\rho$ is estimated as the smallest integer that satisfies $\rho \geq 1$ and

		\begin{equation*}
		    \begin{aligned}
		        (1-q^{\rho+1})^{n-1} > R
		    \end{aligned}
		\end{equation*}

        which can be re-arranged as:

        \begin{equation*}
		    \begin{aligned}
		        \rho > \frac{ln(1-R)}{ln(q)} -1 \qquad \mbox{\emph{where}} \qquad R=(R)^{\frac{1}{n-1}}
		    \end{aligned}
		\end{equation*}

        The inequality assumes that $m$ is multicast exactly ($\rho +1$) times in a crash-free manner and all $n-1$  intended recipients are operative. Both assumptions lead to a \emph{conservative} estimate of $\rho$. Moreover, for a given $R$, an integer $I =0,1, \ldots$, satisfies: 

        \begin{equation*}
		    \begin{aligned}
		        I < \frac{ln(1-R)}{ln(q)}-1 < I+1
		    \end{aligned}
		\end{equation*}
		
        for a wide range of $q$ values; e.g., for $R \approx 0.9999$:

        \begin{equation*}
		    \begin{aligned}
                \frac{ln(1-R)}{ln(q)}-1 < 1 \quad \forall \quad q < 0.01 = 1\%
		    \end{aligned}
		\end{equation*}

        Thus, small inaccuracies in estimating $q$ may not adversely affect $\rho$ estimates.

        \item[\Huge$\boldsymbol{\eta}$] \hfill \\
        $\eta$ is the parameter used by \emph{rbcast} to determine the amount of time to wait between each broadcast of a message copy and is calculated as the largest delay in $n - 1$ transmissions (of a given copy $m$) with probability $R$.  Assuming exponential distribution $n$ is calculated as follows:
        
		% \eta=-\bar{x}[ln(1-R^{\frac{1}{n-1}})]     
		% \eta=-\bar{x}[ln(1-R)]  
        \begin{equation*}
		    \begin{aligned}
		        \eta=-\bar{x}[ln(1-R^{\frac{1}{n-1}})]  
		    \end{aligned}
		\end{equation*}
		
Where $\bar{x}$ is the median of $NT_P$ observed delays.
%Where $\bar{x}$ is the mean of $NT_P$ observed delays.    

        \item[\Huge$\boldsymbol{\omega}$] \hfill \\
        $\omega$ is the parameter utilised by \emph{rbcast} to approximate the PDV encountered by the network.  $\omega$ is simply calculated as:
        
        \begin{equation*}
		    \begin{aligned}
		        \omega = \eta - \bar{x}
		    \end{aligned}
		\end{equation*}        
        
        Again, $\bar{x}$ is the median of $NT_P$ observed delays.
        \end{description}

	    %\paragraph{NMC Validation}\label{a4_validation}\hspace{0pt} \\
            	%We conducted a series of experiments to test \textbf{A4}, which were executed on a local computer cluster.  These experiments consisting of a 
            	% Describe Experiment and execution environment
				% Results
				% Analysis
	    
\section{Atomic Broadcast Protocol}

    \subsection{Aramis}
    
	    \subsubsection{Delivery Conditions}    
	    
		\subsubsection{Delivery Delay}
			% Maths and the rational for their calculation. 
		\subsubsection{Rejected Messages}
			% Messages rejected if a later message has already been delivered.
			% Issue a warning, or throw exception.
		
		% Base delivery conditions
	\subsection{Base}
	% Vector clocks
	% Missing sequences
	% Delivery conditions - All acks sent and received
	
	\subsection{Optimisations}
	% Rho > )
	% Acks piggybacked on subsequent messages
		
\section{Summary}