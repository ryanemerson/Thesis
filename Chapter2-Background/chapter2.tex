%*****************************************************************************************
%*********************************** Second Chapter **************************************
%*****************************************************************************************

 \chapter{Background}

\ifpdf
    \graphicspath{{Chapter2-Background/Figs/Raster/}{Chapter2-Background/Figs/PDF/}{Chapter2-Background/Figs/}}
\else
    \graphicspath{{Chapter2-Background/Figs/Vector/}{Chapter2-Background/Figs/}}
\fi


\section[Network Communication Paradigms]{Network Communication Paradigms}
Solutions to distributed problems are commonly associated with one of two paradigms: Synchronous and Asynchronous communication. Atomic Broadcast protocols are no exception to this rule, therefore in order to understand the challenge of designing and implementing atomic broadcast protocols, it is necessary to explore the limitations of common network paradigms.  

	\subsection{Synchronous}
	Synchronous communication refers to a communication model in which an upper bound can be placed on the communication delay experienced when sending data packets between any two nodes in the network. If a data packet exceeds this upper bound then the transmission is deemed to have failed due to a timing failure, requiring the data packet to be retransmitted. 
	
	In order to successfully calculate the upper bound on communication delays a synchronous network needs to establish an upper bound on the number of faulty nodes present in the network, the maximum load of the network and the transmission rate of data packets~\cite{Cristian:1996:SA:227210.227231}. These requirements make the synchronous paradigm unsuitable for use in middleware and distributed database systems, as such systems are typically executed on commodity hardware.  
	 
	\subsection{Asynchronous}
	The Asynchronous communication model does not define an upper bound on communication or processing delays, instead these delays are considered finite and arbitrary, resulting in the performance bounds required in the synchronous model becoming redundant. Placing no bounds on network load or the number of faulty nodes makes the asynchronous model much more flexible then the synchronous approach, enabling the asynchronous model to be implemented over various network topologies that utilise commodity hardware. 

	A limitation of the asynchronous model is the inability to distinguish between a slow or a crashed node, due to the lack of an established upper bound on communication delays.  Consequently many applications using the asynchronous models must rely on configurable timeout parameters, which can result in \emph{false suspicions}; where a slow node is incorrectly suspected of having crashed.  Conversely, it is also possible for the time outs to be too large, resulting in the system waiting longer than necessary to detect a crashed node.  
	
	\subsection{Probabilistic Synchronous}
	Recent papers have called for an alternative to the asynchronous model to be utilised when designing distributed systems. Aguilera and Walkfish~\cite{Aguilera:2009:NTA:1855568.1855571} argue that the asynchronous model is inherently unsafe. They believe that removing assumptions about synchrony at the lower layers of a system can sacrifice liveness throughout the system. Furthermore the inability to distinguish between a crash and a slow process can result in users of a system having to guess on the appropriate action to take in order to remedy the situation, potentially violating safety. 

Ezhilchelvan and Shrivastava~\cite{Ezhilchelvan:2010:LPR:1773912.1773927} introduce a new communication model, Probabilistic Synchronous Model, which aims to overcome the previously stated issues with asynchrony. The probabilistic synchronous model is based upon the assumption that, in datacentres and cluster-based environments, there is a correlation between the past and near future "performance" of the network; where performance is the probability distribution of delays. In the literature, the existence of this correlation is called stochastic patterns being stationary. The recent past performance of the network can then be used as an input parameter for distributed protocols, which utilise these values to calculate probabilistic guarantees. Monitoring the recent past performance of the network also enables protocols to utilise time outs that are considered accurate to a certain probability, enabling processes to distinguish between slow and crashed nodes. 


\section{Atomic Broadcast Protocols}
Atomic broadcast protocols, \emph{abcast} for short, are message broadcasting protocols that provide specific guarantees on message delivery to ensure that messages are delivered reliably and in the same order at all destinations.  The following guarantees must be maintained to ensure that a broadcast is atomic, with regard to the delivery order and the set of destinations that deliver the message; where delivery is the passing of a message up the network stack to a higher level protocol or application.  

\begin{itemize}
    \item [\textbf{G1}] - \emph{Validity}: If the source of $m_i$ does not crash until it \emph{abcast}s $m_i$, then all operative destinations of $m_i$ deliver $m_i$.
    \item [\textbf{G2}] - \emph{Uniform Agreement}: If the source of $m_i$ crashes while \emph{abcast}ing $m_i$, and if any destination delivers $m_i$, then all operative
destinations of $m_i$ must deliver $m_i$.
    \item [\textbf{G3}] - \emph{Uniform Integrity}: If $m_i$ has already been delivered by a destination $d$, then $d$ cannot not deliver $m_i$ again.  
    \item [\textbf{G4}] - \emph{Uniform Total Order}: If two \emph{\emph{abcast}s}, $m_i$ and $m_j$, have
common destinations, then all such destinations that deliver both $m_i$ and $m_j$, must deliver them in an identical order (i.e. $<m_i, m_j>$ or $<m_j, m_i>$)
\end{itemize}

Message delivery is a one-time, irreversible operation that occurs when a message is passed up from the \emph{abcast} protocol to the next layer in the network stack. Once a message has been delivered, it cannot be undelivered, therefore any violations of message guarantees cannot be undone at the \emph{abcast} level.  Therefore meeting G1-G4 presents two challenges, C1 and C2, that need to be met by all \emph{abcast} protocols.

Consider $m$ is to be \emph{abcast} to a set of destinations $m.dst$, where $m.dst$ contains the source of an \emph{abcast} message, as the receiving of the message incurs no additional network cost and enables the source application to receive its own message.  C1 and C2 are stated below:
\begin{itemize}
    \item[\textbf{C1}] - If an operative $d \in m.dst$ receives $m$, then every operative
     $d' \in m.dst$ must be able to receive $m$ so that G1 and G2 are not violated.
    \item[\textbf{C2}] - Every $d$ that receives $m$ must determine a \emph{safe} moment
to deliver $m$ so that G3 and G4 are not violated.
\end{itemize}

Meeting both C1 and C2 is not a trivial task, as such there is a large amount of literature\cite{Defago:2004:TOB:1041680.1041682} on \emph{abcast} protocols spanning several decades.  From the literature, it is clear that there exists two distinct approaches to solving the challenges of \emph{abcast}; \emph{Quorum based} and \emph{Group Membership} dependent protocols.  This section will describe each of these approaches and explore notable examples of each approach.  
	
    \subsection{Group Ordering}
    \emph{Abcast} protocols can provide two different types of broadcasting capability, some protocols allow messages to only be sent to a single destination set, whereas others allow messages to be sent to multiple subsets of the available destinations.  The merits of each are explored below.   
    
        \subsubsection{Single Destination Set}
        A single destination protocol is a \emph{abcast} protocol that only allows the sending of a message to one set of destinations.  For example if the total number of nodes is equal to 5, then $\left\vert{m.dst}\right\vert = 5$.
        
        Protocols that utilise a single destination set can provide performance benefits over protocols that allow multiple destination groups in scenarios where $\left\vert{m.dst}\right\vert$ is small (< 5).  This is because such protocols can piggyback additional meta information on messages as they know that the nodes in the $m.dst$ set will remain the same in the absence of node failures.  Furthermore, such protocols do not have the overhead of the overlapping subset problem described in \ref{ssec:overlapping}.  
        
        Due to $\left\vert{m.dst}\right\vert$ being equal to the number of total nodes, the scalability of single destination set protocols is underwhelming, with performance degrading dramatically as the number of nodes increase.  
        
        \subsubsection{Multiple Destination Sets}\label{ssec:overlapping}
        In contrast to single destination protocols, there a \emph{abcast} protocols that allow messages to be broadcast to multiple destination sets within the cluster.  Such protocols fall into two categories, those that only allow \emph{disjoint} sets and those that allow \emph{overlapping} sets.  
        
        The creation of disjoint \emph{abcast} protocols is trivial, as the majority of single destination set protocols can be converted into disjoint protocols with only a few minor adjustments \cite{Defago:2004:TOB:1041680.1041682}.  Disjoint protocols are not applicable to Infinispan, as the ability to only broadcast to disjoint sets of destinations does not provides a solution to either the \emph{partial} or \emph{full} replication problem, as described in \ref{sec:infinispan}.  
        
        Creating protocols that support overlapping destination sets is a challenging task, due to any node involved in two overlapping subset having to satisfy G4 for messages involved in both destination sets.  Say node $a$ broadcasts $m_i$ to $m.dst = \{a,b,c\}$ and node $d$ broadcasts $m_j$ to $m.dst = \{b,c,d\}$ the challenge is ensuring that the common destinations $\{b,c\}$ deliver both messages in the same order; either $m_i$ before $m_j$ or vice versa.  Furthermore, solving C2 becomes more difficult as we need to ensure that $\{b,c\}$ do not miss $m_i$ or $m_j$, in a way that is not overly-restrictive on performance.  
        
        
	\subsection{Group Membership based Atomic Broadcast}
	The Group Membership (GM) approach to \emph{abcast} protocols refers to a group of protocols that rely on a higher level service/protocol to maintain a current \emph{view} of nodes that are correct (not crashed).  The \emph{abcast} protocol leaves all crash detection to the GM protocol, and assumes that the latest \emph{view} $v_i$ issued by the GM protocol is representative of the network's current state.  When the GM service detects that a node has crashed, it publishes a new view $v_j$, which the \emph{abcast} protocol will utilise until a subsequent view is published.  The \emph{abcast} protocol is responsible for ensuring that guarantees G1-G4 are maintained by taking appropriate action upon receiving a new view from the GM service.  
	
	GM dependent protocols always operate on the assumption that the current view $v_i$ provided by the GM protocol is accurate.  A consequence of this is that when $v_i$ no longer represents the actual state of the network, $\left\vert v_i \right\vert \neq \left\vert ActiveNodes \right\vert$, the \emph{abcast} protocol will block severely until $v_j$ is published.  This blocking will result in a loss of availability for any \emph{abcast} messages required by higher level protocols/applications, however it is necessary to ensure that G1-G4 are maintained.  Upon receiving $v_j$, the \emph{abcast} protocol will safely remove any messages that have been received from the crashed node, but have not yet been delivered by any destination (G1).  A \emph{virtually-synchronous}\cite{Birman:1991:LCA:128738.128742} closure is typically used to ensure that all \emph{abcast} messages sent by the crashed node, that have been delivered by at least one correct destination, are delivered by all of the remaining destinations (G2).  

        \subsubsection{Newtop}
        Newtop \citep{Ezhilchelvan:1995:NFG:876885.880005} is a GM based \emph{abcast} protocol developed by Ezhilchelvan et al. that supports broadcasting to overlapping destination sets.  It utilises acknowledgements and logical clocks, to ensure that C1 and C2 are met, respectively.  
        
        To ensure that C1 is met, the delivery of a message $m$, sent by $d$, $m.o=d$, is blocked until each $d' \in m.dst-\{m.o\}$ has acknowledged $m$ by sending $ack_{d'}(m)$ to every $d \in m.dst$ and each $d \in m.dst$ has received $ack_{d'}(m) \forall m.dst \setminus \{m.o,d\}$.  This ensures that it is impossible to violate C1, as every $d$ has confirmation that $m$ has been received by all members of $m.dst$.  
        C2 is addressed by each $m$ and each $ack_{d'}(m)$ being \emph{tentatively} timestamped with a value that is one more than the timestamp ever seen or used by the respective source \cite{Lamport:1978:TCO:359545.359563}. Once $m$ and the $ack_{d'}(m)$ of every $d'\in m.dst-\{m.o\}$ are received, $d \in m.dst$ \emph{finalizes} a timestamp ($m.ts$) for $m$ as the largest of all these tentative timestamps. When $d$ delivers every received $m$ as per (finalized) $m.ts$, all guarantees are met. Proofs are in \cite{Lamport:1978:TCO:359545.359563, Birman:1991:LCA:128738.128742, Ezhilchelvan:1995:NFG:876885.880005} and the intuition is given below.
        
        Since $m.ts$ is finalized only after having received a tentative timestamp from every node in $m.dst$, for any $d \in m.dst$, $m.ts$ cannot be smaller than any of the tentative timestamps proposed for $m$, when $d$ finalizes $m.ts$, it must have received any $m'$ whose $m'.ts$ \emph{could} be finalized as $m'.ts < m.ts$. So, if $d$ finalizes $m.ts$ before finalizing $m'.ts$, it will wait for $m'.ts$ to be finalized before delivering $m$.
        
        Say, $d' \in m'.dst - \{m.o\}$ is crashed; When $d \in m'.dst$ does not receive $ack_{d'}(m')$, it is blocked from finalizing $m'.ts$ until the GM protocol confirms that $d'$ is crashed and $ack_{d'}(m')$ does not exist (through \emph{virtually synchronous} closure). Say, $d$ has proposed $ack_d(m').ts$ and also it finalizes some $m.ts$ while $d'$ remains crashed (Note: $d'$ is not in $m.dst$). If $m.ts > ack_d(m').ts$, $d$ is also blocked from delivering $m$ until $m'.ts$ is finalized, because $d$ knows that $m'.ts$ can be finalized as $m'.ts < m.ts$.

Thus, when \emph{abcast}s are initiated by an application , the longer GM takes to detect and isolate a crashed node (such as $d'$ above), the larger the number of nodes (such as $d$) that are likely to receive an \emph{abcast} (such as $m'$) whose destination set includes the crashed one and, at each such node, the larger is the number of finalized \emph{abcast}s (such as $m$) blocked from delivery.  Ultimately leading to a loss in the system's liveness.  

Although the Newtop protocol blocks severely in the presence of node crashes, in their absence it provides the smallest achievable latency available to \emph{abcast} protocols.  This is because Newtop finalises $m.ts$ within $2 \times x_{mx}$, where $x_{mx}$ is the maximum message latency between the nodes in $m.dst$.  Therefore allowing the protocol to deliver messages within $2 \times x_{mx}$ when blocking does not occur.  

Finally, if the Newtop protocol is utilised in an single destination environment, it is possible to finalise $m.ts$ and deliver messages with a single broadcast from $m.o$.  This is achieved by all $d$ piggybacking $ack_d(m)$ on subsequent messages, therefore reducing the load on the network and increasing throughput.  

	\subsection{Quorum Based Atomic Broadcast}
	Quorum based \emph{abcast} protocol are \emph{abcast} solutions that utilise a \emph{master} node to coordinate \emph{slave} nodes.  The master node is responsible for sending all messages, and proposing $m.ts$, which is confirmed when it receives $ack(m)$ from a majority of nodes; hence the name quorum-based.  Thus each \emph{abcast} requires 3 communication steps and latency can be $3 \times x_{mx}$.  
	
	The advantages of such protocols is that they preserve liveness in the presence of node failures, this is because messages can still be delivered, without blocking, when the number of slave failures is less than $\vert\vert \frac{m.dst}{2} \vert\vert - 1$.  However, mild blocking does occur when the master node is suspected of crashing, as it is necessary for a new master node to be elected before \emph{abcast} delivery can resume. Furthermore, as the master node requires a quorum of acknowledgements to proceed, it is not possible for such protocols to be utilised when $\left\vert m.dst \right\vert < 3$. 
	
	Finally, providing support for multiple destination sets in a quorum based protocol is a non-trivial task, which is beyond the scope of this thesis, therefore we will not consider it.  
		\subsubsection{Paxos}
		\subsubsection{RAFT}		
	

\section{Coordination Services}
Coordination services are centralised systems that can be utilised by distributed systems to provide commonly required services that aid process coordination. Examples of such services are: distributed lock management, low-volume storage and naming. System engineers can implement these features without using a coordination service, however these features are very complex due to their distributed nature. A coordination service hides this complexity, enabling the engineer to focus on the core functionality of their system. Furthermore, incorporating a coordination service into an existing system only requires calls to the services api, whereas, retrospectively introducing distributed services into even the simplest of systems is fraught with difficulties. 

Coordination systems are usually used by a system to store data that is crucial to their operation, therefore high availability and fault-tolerance are required. Typically, coordination services consist of a small number up of nodes (no greater than ten) that are all replicas of each other, allowing the coordination system to carry on functioning in the presence of node failures. The use of multiple nodes can also increase the number of requests that the coordination service can process simultaneously. 

In order for a coordination service to maintain replicated nodes consistently, it is necessary for a consensus to be reached when writing data to each of the replicas. Without consensus the system's data replicas would become inconsistent, which could be catastrophic for the user system's data consistency and integrity, as they could receive corrupt data from one of the inconsistent replicas. 

	\subsection{Chubby}
	Chubby ~\cite{Burrows:2006:CLS:1298455.1298487} is a distributed lock manager developed by Google that is based upon the Paxos~\cite{Lamport:1998:PP:279227.279229}~\cite{Lamport:2001:PaxosMadeSimple} consensus algorithm. Chubby cluster's typically contain five nodes, however only one node is able to service read and write requests at any one time; this node is called the master. The role of the master is to service client requests and to ensure that all write requests are executed by the replicas. Client write requests are forwarded to all data replicas using the Paxos consensus algorithm, and the request is confirmed to the client when the majority of replicas have executed the write request. 

The main advantage of the Chubby system is its focus on high availability and reliability, with production instances reported to have executed for over a year. However, the limitations of the chubby system are caused by its use of a master node. Utilising a single node to handle all read/write requests severely limits the throughput capabilities of the system because the master node will always become a bottleneck as throughput increases.  Furthermore, because Chubby utilises the Paxos consensus algorithm, the minimum number of nodes in a chubby coordination service is 3 as a quorum needs to be reached between service members.  This can be a disadvantage in systems where fast writes are required, and the use of 3 nodes for fault-tolerance is excessive.  

	\subsection{Zookeeper}
	Zookeeper ~\cite{Hunt:2010:ZWC:1855840.1855851} is an open source general purpose coordination service developed by The Apache Software Foundation. Similar to Chubby, Zookeeper also employs a master node, as it utilises the quorum-based protocol ZAB ~\cite{Junqueira:2011:ZHB:2056308.2056409} to update the data replicas.  However, unlike Chubby, in Zookeeper read requests by clients are not restricted to the master node, rather any replica node can handle them.  This is advantageous, as it reduces the number of requests that the master node has to handle, enabling the master to concentrate on maintaining a consistent state between replicas (i.e. handling write requests) and satisfying its own read requests.  
	
	Distributing read requests across the entire Zookeeper cluster mitigates the bottleneck observed in the Chubby approach, however it does not remove it as all write requests must be served by the master, thus Zookeeper favours workloads that have a read/write ratio of 10:1. Furthermore, when read requests are handled by the replica nodes it is possible for stale values to be returned to the requesting client.  This occurs if a client requests a value from a replica that has missed an \emph{abcast} by the master node, due to the replica not being involved in the quorum.  Therefore, the guarantees provided by Zookeeper can only be considered weakly-consistent.   

%\section{Transactions}

\section{In-memory Databases}
In-memory databases \citep{Infinispan, Hazelcast, GridGain} are database systems that aim to provide scalable, low-latency data storage.  Data is stored in RAM to provide fast data access, and is partitioned across multiple nodes in a cluster for scalability.  In order to provide availability in the presence of node failures, each partition is replicated across distinct nodes; the number of nodes utilised is the \emph{Replication Factor} ($RF$).  Storing data in RAM provides superior read/write performance to traditional disk-based databases, whilst the distributed nature of the database allows it to elastically scale by simply adding additional nodes to store data partitions.  

The emergence of simpler NoSQL based data models, such as key/value pairs, has enabled in-memory databases to become a reality.  Previously, RDBMS services were the de facto standard for database solutions, however their rigid structure greatly limits their ability to elastically scale due to the difficulty of maintaining table structures and distributing records across multiple nodes \citep{Cattell:2011:SSN:1978915.1978919, Cooper:2010:BCS:1807128.1807152}. Distributing data across many nodes is essential for in-memory databases, not only to provide availability, but to provide sufficient storage capacity for a database system; RAM per node is typically measured in gigabytes, whereas disk based storage is measured in terabytes.  

Finally, due to RAM being a volatile storage medium (i.e its state is lost when power is lost) it is common for in-memory databases to provide a means for persistent storage in the event of power-loss or node crashes.  Typically, this is achieved through asynchronous write-requests to a persistent database that utilises the same data model as the in-memory database.  However, in some deployments, such as distributed caches, this is forsaken in order to provide applications with the lowest possible response time.  
    
    \subsection{Replication Schemes}
	Typically, in-memory databases offer two types of replication schemes: \emph{full} and \emph{partial} replication.  
	
	In a \emph{full} replication scheme, each data partition is replicated on every distinct node in the cluster, $RF = \left\vert nodes \right\vert$.  This greatly limits the scalability of the database, as the total number of RPCs required to update each key/value pair increases when additional nodes are added to the cluster.  Furthermore, the maximum storage capacity of the database will always be equal to the RAM size of the least capable node in the cluster.  The advantages of using \emph{full} replication is that it can provide high availability, with only a few cluster nodes, as well as providing high-performance when workloads are read dominant; full replication is extremely effective for creating highly-available distributed cache that sits between the application and a persistent database.  
	
	\emph{Partial} replication is a data scheme, where each data partition is replicated across a subset of nodes in the cluster, $RF < \left\vert nodes \right\vert$; no node holds all replicas of a given partition nor the entire database.  The advantage of this partial replication, is the total size of the database is not limited by the weakest node, rather the collective memory pool of all nodes in the cluster and the $RF$ configured by the system administrator.  Therefore, elastic scalability is possible as the database's capacity can be increased by simply adding an additional node to the cluster.  Ultimately, the scalability of a partially replicated database is determined by the size of $RF$; a high $RF$ value ($RF > 3$) will provide high levels of availability and fault-tolerance at the expense of write latency (as all $RF$ replicas need to be updated); whereas too low a value will provide low-latency writes at the expense of fault-tolerance and availability.   
	
	The total capacity of a partially replicated database can be expressed as $\frac{Mem - S.Res}{RF}$: where $Mem$ is the total amount of RAM available across the cluster, $S.Res$ is the RAM required by other system resources (operating system etc.) and $RF$ is the configured \emph{replication factor}.  

%Persistence is typically provided through asynchronous write-requests, however performance can be improved further by utilising a purely in-memory solution.  tx logs, sacrifice durability in ACID because of volatile nature

\section{Infinispan}\label{sec:infinispan}
	\subsection{Infinispan Requirements}
	\subsection{Atomic Broadcast > 2PC}
		\subsubsection{Advantages of Atomic Broadcast}
		\subsubsection{Current Protocol}
		\subsubsection{Limitations of Existing Protocol}

%\section{RMSys}
%RMSys is a probabilistic broadcast protocol developed by Ezhilchelvan et al.~\cite{rmsys} that utilises the probabilistic synchronous model. It aims to provide the application with probabilistic guarantees on end-to-end message delivery and latency. These guarantees are calculated by RMSysâ€™s Evaluation Component (EC) based upon the recent performance of the network and the requirements of the application. The recent performance of the network is periodically assessed by the Network Measurement Component (NMC) in order to build a Cumulative Distribution Function (CDF) of message latencies. This CDF is delivered to the EC, which uses this data to calculate the probabilistic guarantees that are delivered to the application.  
%
%Initial experiments with RMSys provided encouraging results: (i) stationary assumption holds, and (ii) timeliness and reliability can be close to probability 1. These results, and the benefits of using the probabilistic synchronous model, convinced us that RMSys was a suitable foundation for our atomic broadcast solution. 