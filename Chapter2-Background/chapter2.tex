 \chapter{Background}

% **************************** Define Graphics Path **************************
    \graphicspath{{Chapter2-Background/Figs/Vector/}{Chapter2-Background/Figs/}}

\section[Network Communication Paradigms]{Network Communication Paradigms}
Solutions to distributed problems are commonly associated with one of two paradigms: Synchronous and Asynchronous communication. Each paradigm has defining characteristics that can be both beneficial and limiting depending on a system's requirements.  This section defines both of the common paradigms, before introducing a third paradigm that is central to our research.  

	\subsection{Synchronous}
	Synchronous communication refers to a communication model, in which, an upper bound can be placed on the communication delay experienced when sending data packets between any two nodes in the network. If a data packet exceeds this upper bound then the transmission is deemed to have failed due to a timing failure, requiring the data packet to be retransmitted. 
	
	In order to successfully calculate the upper bound on communication delays a synchronous network needs to establish an upper bound on the number of faulty nodes present in the network, the maximum load of the network and the transmission rate of data packets\citep{Cristian:1996:SA:227210.227231}. These requirements make the synchronous paradigm unsuitable for use in middleware and distributed database systems, as such systems are typically executed on commodity hardware.  Therefore, none of our contributions utilise the synchronous paradigm.  
	 
	\subsection{Asynchronous}
	The Asynchronous communication model does not define a known upper bound on communication or processing delays, instead these delays are considered finite and arbitrary, resulting in the performance bounds required in the synchronous model becoming redundant\citep{Cristian:1996:SA:227210.227231}. Placing no bounds on network load or the number of faulty nodes makes the asynchronous model much more flexible than the synchronous approach, enabling the asynchronous model to be implemented over various network topologies that utilise commodity hardware. 

	A limitation of the asynchronous model is the inability to distinguish between a slow or a crashed node, due to the lack of an established upper bound on communication delays.  Consequently many applications using the asynchronous model must rely on configurable timeout parameters, which can result in \emph{false suspicions}; where a slow node is incorrectly suspected of having crashed.  Conversely, it is also possible for the time outs to be too large, resulting in the system waiting longer than necessary to detect a crashed node.  
	
	The inability to distinguish between slow and crashed nodes leads to the FLP impossibility discovered by Fischer, Lynch and Patterson\citep{Fischer:1985:IDC:3149.214121}.  The FLP impossibility formally proves that it is impossible for distributed consensus to be achieved in an asynchronous environment when a single crashed node is present. 
	
	\subsection{Probabilistically Synchronous}\label{ssec:probabilistically_synchronous}
	Recent papers have called for an alternative to the asynchronous model to be utilised when designing distributed systems. Aguilera and Walkfish\citep{Aguilera:2009:NTA:1855568.1855571} argue that the asynchronous model is inherently unsafe. They believe that removing assumptions about synchrony at the lower layers of a system can sacrifice liveness throughout the system. Furthermore the inability to distinguish between a crash and a slow process can result in users of a system having to guess on the appropriate action to take in order to remedy the situation, potentially violating safety. 

Ezhilchelvan and Shrivastava\citep{Ezhilchelvan:2010:LPR:1773912.1773927} introduce a new communication model, Probabilistic Synchronous Model (PSM), which aims to overcome the previously stated issues with asynchrony. PSM is based upon the assumption that, in datacentres and cluster-based environments, there is a correlation between the past and near future "performance" of the network; where performance is the probability distribution of delays.  The recent past performance of the network can then be used as an input parameter for distributed protocols, which utilise these values to calculate probabilistic guarantees. Monitoring the recent past performance of the network also enables protocols to utilise time outs that are considered accurate to a certain probability, $R$.  Therefore enabling processes to be distinguished as either slow or crashed with the probability of \emph{false suspicions} being $1 - R$.  

\section{Atomic Broadcast and Multicast Protocols} \label{sec:atomic_guarantees}
Atomic broadcast and atomic multicast protocols, \emph{abcast} and \emph{amcast} for short, are \emph{one-to-many} network protocols that provide specific guarantees on message delivery to ensure that messages are delivered reliably and in the same order at all destinations; where delivery is the passing of a message up the network stack to a higher level protocol or application.  

Below we consider the guarantees required by broadcast and multicast protocols, in order for them to be considered atomic.  For the purpose of brevity, we refer only to \emph{abcast} here, however these guarantees also apply to \emph{amcast}s.  The following guarantees must be maintained to ensure that a broadcast is atomic, with regard to the delivery order and the set of destinations that deliver the message.  

\begin{itemize}
    \item [\textbf{G1}] - \emph{Validity}: If the source of $m_i$ does not crash until it \emph{abcast}s $m_i$, then all operative destinations of $m_i$ deliver $m_i$.
    \item [\textbf{G2}] - \emph{Uniform Agreement}: If the source of $m_i$ crashes while \emph{abcast}ing $m_i$, and if any destination delivers $m_i$, then all operative
destinations of $m_i$ must deliver $m_i$.
    \item [\textbf{G3}] - \emph{Uniform Integrity}: If $m_i$ has already been delivered by a destination $d$, then $d$ cannot deliver $m_i$ again.  
    \item [\textbf{G4}] - \emph{Uniform Total Order}: If two \emph{\emph{abcast}s}, $m_i$ and $m_j$, have
common destinations, then all such destinations that deliver both $m_i$ and $m_j$, must deliver them in an identical order (i.e. either $<m_i, m_j>$ or $<m_j, m_i>$)
\end{itemize}

As previously stated, message delivery is a one-time, irreversible operation that occurs when a message is passed up from the \emph{abcast} protocol to the next layer in the network stack. Once a message has been delivered, it cannot be undelivered, therefore any violations of message guarantees cannot be undone at the \emph{abcast} level.  Therefore meeting G1-G4 presents two challenges, C1 and C2, that need to be met by all \emph{abcast} protocols.

Consider $m$ is to be \emph{abcast} to a set of destinations $m.dst$, where $m.dst$ contains the source of an \emph{abcast} message, as the receiving of the message incurs no additional network cost and enables the source application to receive its own message.  C1 and C2 are stated below:
\begin{itemize}
    \item[\textbf{C1}] - If an operative $d \in m.dst$ receives $m$, then every operative
     $d' \in m.dst$ must be able to receive $m$ so that G1 and G2 are not violated.
    \item[\textbf{C2}] - Every $d$ that receives $m$ must determine a \emph{safe} moment
to deliver $m$ so that G3 and G4 are not violated.
\end{itemize}

Meeting both C1 and C2 is not a trivial task, as such there is a large amount of literature\cite{Defago:2004:TOB:1041680.1041682} on \emph{abcast} protocols spanning several decades.  From the literature, it is clear that there exists two distinct approaches to solving the challenges of \emph{abcast} and \emph{amcast}; \emph{Quorum based} and \emph{Group Membership} dependent protocols.  This section will describe each of these approaches and explore notable examples of each approach.  
	
	\subsection{Atomic Broadcast vs Atomic Multicast}
	So far we have considered \emph{abcast} and \emph{amcast} protocols to be \emph{one-to-many} network protocols, that must satisfy guarantees G1-G4 in order to be considered atomic.  However, there are key differences between broadcast and multicast protocols.  Below we provide a definition for both broadcast and multicast protocols and explore the strengths and limitations of each type.  
	
	\subsection{Broadcast}\label{ssec:atomic_broadcast}
	In the literature\cite{Defago:2004:TOB:1041680.1041682} broadcast protocols, and hence \emph{abcast}, are defined as a \emph{one-to-many} network protocols that only allow messages to be sent between a single destination set, with all destinations in the set receiving each broadcast.  For example if the total number of destinations is equal to 5, then $\left\vert{m.dst}\right\vert = 5$ is always true.
	
	Restricting \emph{one-to-many} communication to a single destination set can provide performance benefits over protocols that allow multiple destination sets, when the size of the destination set is small ($e.g. \left\vert{m.dst}\right\vert < 5$).   This is because such protocols can employ various optimisations, such as as piggybacking meta information on messages, as they know that $m.dst$ remain the same for all broadcasts when no node failures occur.  Furthermore, broadcast protocols do not have the overhead of handling more complex message routing problems such as the overlapping subset problem described in \ref{ssec:atomic_multicast}.  
	
	Due to $m.dst$ always being the same, the scalability of single destination set protocols is underwhelming, with performance degrading dramatically as the number of destinations increase.  
	
	\subsection{Multicast}\label{ssec:atomic_multicast}
	In contrast to broadcast protocols, multicast protocols allow messages to be sent to multiple destination sets.  Such protocols fall into two categories, those that only allow \emph{disjoint} destination sets and those that allow \emph{overlapping} destination sets.  
	
	The creation of disjoint \emph{amcast} protocols is trivial, as the majority of \emph{abcast} protocols can be converted into disjoint protocols with only a few minor adjustments \cite{Defago:2004:TOB:1041680.1041682}.  Disjoint protocols are not applicable to Infinispan, as the ability to only multicast to disjoint sets of destinations does not provides a solution to either the \emph{partial} or \emph{full} replication problem, as described in \ref{sec:infinispan}.  
        
        Creating \emph{amcast} protocols that support overlapping destination sets is a challenging task, as any destination contained in two overlapping subsets has to satisfy G4 for all messages involved in both destination sets.  Say node $a$ multicasts $m_i$ to $m.dst = \{a,b,c\}$ and node $d$ multicasts $m_j$ to $m.dst = \{b,c,d\}$ the challenge is ensuring that the common destinations $\{b,c\}$ deliver both messages in the same order; either $m_i$ before $m_j$ or vice versa.  Furthermore, solving C2 becomes more difficult as we need to ensure that $\{b,c\}$ do not miss $m_i$ or $m_j$, in a way that is not overly-restrictive on performance.  
        
       It is worth noting that, by definition, a \emph{amcast} protocol can always be converted to a \emph{abcast} protocol as the multicast protocol can simply multicast all messages with the same destination set.  
       
	\subsection{Group Membership based approaches}
    This section details the Group Membership (GM) approach to solving the problem of creating \emph{abcast} and \emph{amcast} protocols, before providing an example of a GM based \emph{amcast} protocol.  For the remainder of this section, we consider \emph{amcast} protocols, however the use of GM is also applicable to \emph{abcast}.  
	
	The GM approach to \emph{amcast} protocols refers to a group of protocols that rely on a higher level service/protocol to maintain a current \emph{view} of nodes that are correct (not crashed).  The \emph{amcast} protocol leaves all crash detection to the GM protocol, and assumes that the latest \emph{view} $v_i$ issued by the GM protocol is representative of the network's current state.  When the GM service detects that a node has crashed, it publishes a new view $v_j$, which the \emph{amcast} protocol will utilise until a subsequent view is published.  The \emph{amcast} protocol is responsible for ensuring that guarantees G1-G4 are maintained by taking appropriate action upon receiving a new view from the GM service.  
	
	GM dependent protocols always operate on the assumption that the current view $v_i$ provided by the GM protocol is accurate.  A consequence of this is that when $v_i$ no longer represents the actual state of the network, $\left\vert v_i \right\vert \neq \left\vert ActiveNodes \right\vert$, the \emph{amcast} protocol will block until $v_j$ is published.  This blocking will result in a loss of availability for any \emph{amcast} messages required by higher level protocols/applications, however it is necessary to ensure that G1-G4 are maintained.  Upon receiving $v_j$, the \emph{amcast} protocol will safely remove any messages that have been received from the crashed node, but have not yet been delivered by any destination (G1).  A \emph{virtually-synchronous}\cite{Birman:1991:LCA:128738.128742} closure is typically used to ensure that all \emph{amcast} messages sent by the crashed node, that have been delivered by at least one correct destination, are delivered by all of the remaining destinations (G2).  

        \subsubsection*{Newtop} \label{ssec:newtop}
        Newtop\citep{Ezhilchelvan:1995:NFG:876885.880005} is a GM based \emph{amcast} protocol developed by Ezhilchelvan \emph{et al.} that supports multicasting to overlapping destination sets.  It utilises acknowledgements and logical clocks, to ensure that C1 and C2 are met, respectively.  
        
        To ensure that C1 is met, the delivery of a message $m$, sent by $d$, $m.o=d$, is delayed until each $d' \in m.dst-\{m.o\}$ has acknowledged $m$ by sending $ack_{d'}(m)$ to every $d \in m.dst$ and each $d \in m.dst$ has received $ack_{d'}(m) \forall (m.dst \setminus \{m.o,d\})$.  This ensures that it is impossible to violate C1, as every $d$ has confirmation that $m$ has been received by all members of $m.dst$.
        C2 is addressed by each $m$ and each $ack_{d'}(m)$ being \emph{tentatively} timestamped with a value that is one more than the timestamp ever seen or used by the respective source \cite{Lamport:1978:TCO:359545.359563}. Once $m$ and the $ack_{d'}(m)$ of every $d'\in m.dst-\{m.o\}$ are received, $d \in m.dst$ \emph{finalizes} a timestamp ($m.ts$) for $m$ as the largest of all these tentative timestamps. 
        
        Figure \ref{fig:newtop} shows how timestamps and logical clocks are used to finalise a timestamp for a given $m$; where each node's logical clock is represented as LC and each message contains a reference to $m$, the address of the source node sending the message and the associated timestamp.  

    \begin{figure}[htbp!] 
                \centering    
                \includegraphics[width=1.0\textwidth]{Newtop}
                \caption[Newtop Atomic Multicast Protocol]{Newtop Protocol Sequence Diagram}
                \label{fig:newtop}
            \end{figure}	          
        
        When $d$ delivers every received $m$ as per (finalized) $m.ts$, all guarantees are met. Proofs are in \cite{Lamport:1978:TCO:359545.359563, Birman:1991:LCA:128738.128742, Ezhilchelvan:1995:NFG:876885.880005} and the intuition is given below.
        
        Since $m.ts$ is finalized only after having received a tentative timestamp from every node in $m.dst$, for any $d \in m.dst$, $m.ts$ cannot be smaller than any of the tentative timestamps proposed for $m$, when $d$ finalizes $m.ts$, it must have received any $m'$ whose $m'.ts$ \emph{could} be finalized as $m'.ts < m.ts$. So, if $d$ finalizes $m.ts$ before finalizing $m'.ts$, it will wait for $m'.ts$ to be finalized before delivering $m$.
        
        Say, $d' \in m'.dst - \{m.o\}$ is crashed; When $d \in m'.dst$ does not receive $ack_{d'}(m')$, it is blocked from finalizing $m'.ts$ until the GM protocol confirms that $d'$ is crashed and $ack_{d'}(m')$ does not exist (through \emph{virtually synchronous} closure). Say, $d$ has proposed $ack_d(m').ts$ and also it finalizes some $m.ts$ while $d'$ remains crashed (Note: $d'$ is not in $m.dst$). If $m.ts > ack_d(m').ts$, $d$ is also blocked from delivering $m$ until $m'.ts$ is finalized, because $d$ knows that $m'.ts$ can be finalized as $m'.ts < m.ts$.
        
         \begin{figure}[htbp!] 
                \centering    
                \includegraphics{Newtop-Ts}
                \caption[Newtop Timestamp Blocking]{Newtop Timestamp Blocking Diagram}
                \label{fig:newtop-ts}
            \end{figure}

Figure \ref{fig:newtop-ts}, shows the stages detailed above.  Messages $m_1$ cannot be delivered until $m'.ts$ has been finalised, \emph{i.e.} the crashed node $d'$ has been detected by the GM service and node $d$ finalises $m'.ts$ as it knows that $ack_{d'}(m')$ will never be received.  The largest proposed $ts$ for $m_i$ can only increase with time, therefore the longer the GM service takes to detect $d'$ has crashed, the larger $n$ in the figure becomes.  Thus, when \emph{amcast}s are initiated by an application, a large delay between a node crashing and the GM service detecting it, results in an increased probability of many nodes receiving \emph{amcast}s that have the crashed node in their destination set.  As the number of nodes participating in \emph{amcast}s involving the crashed node increases, the size of $n$ also increases, resulting in more finalized \emph{amcast}s that cannot be delivered to the application. Ultimately leading to a loss in the system's liveness, as no progress can be made by any node waiting for an acknowledgement from a crashed node, until the GM service detects the node crash.  

Although the Newtop protocol blocks in the presence of node crashes, in their absence it provides the smallest achievable latency available to \emph{amcast} protocols.  This is because Newtop finalises $m.ts$ within $2 \times x_{mx}$, where $x_{mx}$ is the maximum message latency between the nodes in $m.dst$.  Therefore allowing the protocol to deliver messages within $2 \times x_{mx}$ when blocking does not occur.  

Finally, if the Newtop protocol is utilised in a single destination environment, hence as a \emph{abcast} protocol, it is possible to finalise $m.ts$ and deliver messages with a single broadcast from $m.o$.  This is achieved by all $d$ piggybacking $ack_d(m)$ on subsequent messages, therefore reducing the load on the network and increasing throughput.  

	\subsection{Quorum Based approach}
	 This section details the canonical example of a Quorum based \emph{abcast} protocol. It is possible to solve \emph{amcast} utilising a quorum based protocol is possible, however it is a non-trivial task which is beyond the scope of this thesis, therefore we only consider \emph{abcast} protocols.  
	 
	Quorum based \emph{abcast} protocol are \emph{abcast} solutions that utilise a \emph{master} node to coordinate \emph{slave} nodes.  The master node is responsible for sending all messages, and proposing $m.ts$, which is confirmed when it receives $ack(m)$ from a majority of nodes; hence the name quorum-based.  Thus each \emph{abcast} requires at least 3 communication steps, resulting in a minimum latency of $3 \times x_{mx}$.  
	
	The advantages of such protocols is that they preserve liveness in the presence of node failures, this is because messages can still be delivered, without blocking, when the number of slave failures is less than $\vert\vert \frac{m.dst}{2} \vert\vert - 1$.  However, mild blocking does occur when the master node is suspected of crashing, as it is necessary for a new master node to be elected before \emph{abcast} delivery can resume. Furthermore, as the master node requires a quorum of acknowledgements to proceed, it is not possible for such protocols to be utilised when $\left\vert m.dst \right\vert < 3$. 
		
		\subsubsection*{Paxos}
		Paxos\citep{Lamport:1998:PP:279227.279229}\citep{Lamport:2001:PaxosMadeSimple} is arguably the most famous distributed consensus algorithm, in part because of its notoriety as a difficult algorithm to understand, but more notably that it was the first provably resilient consensus algorithm for asynchronous networks.  Although the FLP \citep{Fischer:1985:IDC:3149.214121} impossibility states it is impossible for a deterministic consensus algorithm to guarantee progress in the presence of node failures, Paxos is considered \emph{resilient} as it guarantees safety, at the expense of availability, in such circumstances.  As consensus and \emph{abcast} are equivalent problems\citep{Defago:2004:TOB:1041680.1041682}, it is common for Paxos to be utilised for \emph{abcast}.  
		
		Although the Paxos algorithm has a reputation for being difficult to understand and even harder to implement, the protocol has been widely utilised in both research and industrial settings.  The most famous example of which is its use in the distributed locks system Chubby \citep{Burrows:2006:CLS:1298455.1298487}, which was created by Google for coordinating their internal services.  In addition to the basic Paxos algorithms, there exists many variations of Paxos that allow the protocol to cater for different application needs \citep{DBLP:journals/corr/MarandiBPB14}, such as: handling byzantine failures \citep{DBLP:conf/wdag/Lamport11a}, reducing total message cost \citep{DBLP:conf/dsn/LamportM04}, reducing latency \citep{DBLP:journals/dc/Lamport06} and increasing throughput \citep{marandi2010ring, Santos:2012:TPH:2183677.2183688}.  
		
		In addition to this suite of Paxos protocols, there is also the increasingly popular RAFT protocol developed at Standford University by Ongaro \emph{et al.} \citep{Ongaro:2014:SUC:2643634.2643666}.  RAFT provides all of the safety guarantees provided by Paxos, however it has been designed with understandability and simplicity of implementation in mind.  This has led to widespread adoption of the protocol in distributed systems, with open source implementations of the language now available for the majority of main stream programming languages.  
		
		The remainder of this section provides a brief overview of how the basic Paxos algorithm can work as an \emph{abcast} protocol.  We examine the protocol from the perspective of both master and slave nodes.  
		
		\begin{description}
		    \item[Master] \hfill
			    \begin{enumerate}
		  			\item Propose, $propose(m, p.s)$, an \emph{abcast} $m$ to $m.dst$ with a sequence number $p.s$.
		  			\item Wait $x$ amount of time for a quorum of nodes to respond.  If a quorum cannot be reached in $x$ then abort and start a new proposal.  If a quorum is reached in favour of rejecting $p.s$, then record the largest sequence number returned $p.s'$, set the masters local sequence to greater than $p.s'$ and start a new proposal.  If a quorum is reached in favour of accepting $p.s$, then send a commit $commit(m, p.s)$ to all $m.dst$.  
		  			\item If the majority of $m.dst$ respond with an accept $accept(m, p.s)$ message, then the \emph{abcast} is considered successful, otherwise start a new proposal.  
			\end{enumerate}
			
			
			\item[Slave] \hfill
				\begin{enumerate}
		  			\item Upon receiving a proposal, compare its sequence $p.s$ with the highest sequence that this node has currently agreed to, $p.s'$.  If $p.s > p.s'$ then reply with an $accept(m, p.s)$, otherwise send a $reject(m, p.s)$ message with $p.s'$ to the proposer node.  
		  			\item When a $commit(m, p.s)$ message is received, if this node agreed to $p.s$ then $m$ has to be delivered, otherwise $m$ must be rejected as this node did not participate in the quorum.  
				\end{enumerate}		
		\end{description}
		
\section{Coordination Services}\label{sec:coordination}
Coordination services are centralised systems that can be utilised by distributed systems to provide commonly required services that aid process coordination. Examples of such services are: distributed lock management, low-volume storage and naming. System engineers can implement these features without using a coordination service, however these features are very complex due to their distributed nature\citep{Burrows:2006:CLS:1298455.1298487}. A coordination service hides this complexity, enabling the engineer to focus on the core functionality of their system. Furthermore, incorporating a coordination service into an existing system only requires calls to the services API, whereas retrospectively introducing distributed services into even the simplest of systems is fraught with difficulties. 

Coordination systems are usually used by a system to store data that is crucial to their operation, therefore high availability and fault-tolerance is required. Typically, a coordination services are implemented as a state machine, consisting of a small number up of nodes \footnote{Typically 3-5 nodes and certainly no greater than 10.} that are all replicas of each other.  Maintaining a distributed state machine between service nodes allows the service to maintain availability and continue to service client requests when node failures occur within the service. Utilising multiple nodes can also increase the throughput of the service, as each node can simultaneously process client requests, and in the case of read requests can respond to the client without additional interactions between replica nodes.  

In order to maintain a consistent state across the service's replicas, it is necessary for a consensus to be reached between the replica nodes when a client's request modifies the service's state.  Without consensus the service's state would become inconsistent between replicas and the distributed state machine would no longer be valid.  Such an occurrence could be catastrophic for client applications that depend on the service, as responses from different replicas could return conflicting data, potentially causing an irrecoverable state amongst client nodes.  

	\subsection{Chubby}
	Chubby\citep{Burrows:2006:CLS:1298455.1298487} is a distributed lock manager developed by Google that is based upon the Paxos\citep{Lamport:1998:PP:279227.279229}\citep{Lamport:2001:PaxosMadeSimple} consensus algorithm. Chubby cluster's typically contain five nodes, however only one node is able to service a client's read and write requests at any one time; this node is called the master. The role of the master is to service client requests and to ensure that the state of all replicas is updated when a write operation is requested.  Client write requests are coordinated between replicas using the Paxos consensus algorithm, with a client request being completed when a Quorum of replicas have confirmed the write operation.  
	
Figure \ref{fig:chubby_leader_write} shows the basic steps involved when a write request is received by the chubby master node; the master node receives the client request (stage 1), \emph{abcast}s it to all slave nodes (stage 2), before processing the request locally and sending a response back to the client node (stage 3).  

	\begin{figure}[htbp!] 
	    \centering    
	    \includegraphics[width=1.0\textwidth]{chubby_leader_write}
	    \caption[Chubby Write Request at Master Node]{Chubby Write Request at Master Node}
	    \label{fig:chubby_leader_write}
	\end{figure}	 

Figure \ref{fig:chubby_slave_write} shows the steps required if a client request is received by a replica node instead of the master; the replica node forwards the client request to the master node (stage 1), at which point the master node executes the request as if it was originally received by the master node (stages 2-4).

	\begin{figure}[htbp!] 
	    \centering    
	    \includegraphics[width=1.0\textwidth]{chubby_slave_write}
	    \caption[Chubby Write Request at Replica Node]{Chubby Write Request at Replica Node}
	    \label{fig:chubby_slave_write}
	\end{figure}	 

The main advantage of the Chubby system is its focus on high availability and reliability, with production instances reported to have executed for over a year. However, the limitations of the chubby system are caused by its use of a master node. Utilising a single node to handle all read/write requests severely limits the system's throughput as the master node will always become a bottleneck as the number of requests to the service increase.  Furthermore, because Chubby utilises the Paxos consensus algorithm, the minimum number of nodes in a chubby coordination service is 3 as a quorum needs to be reached between service members.  This can be a disadvantage in systems where fast writes are required, and the use of 3 nodes for fault-tolerance is excessive.  
	
	\subsection{Zookeeper}
	Zookeeper\citep{Hunt:2010:ZWC:1855840.1855851} is an open source general purpose coordination service released under the Apache Software License Version 2.0 \citep{ApacheLicense}. Similar to Chubby, Zookeeper also employs a master node, as it utilises the quorum-based protocol ZAB\citep{Junqueira:2011:ZHB:2056308.2056409} to update each replica.  However, unlike Chubby, in Zookeeper read requests from client nodes are not restricted to the master node, rather any replica node can handle them.  This is advantageous, as it reduces the number of requests that the master node must handle, enabling the master to focus on servicing write requests and processing its own read requests.  
	
\begin{figure}[htbp!] 
	    \centering    
	    \includegraphics[width=1.0\textwidth]{zookeeper_read}
	    \caption[Zookeeper Read and Write Requests]{Zookeeper Write at Master, and Read at Replica Node}
	    \label{fig:zookeeper_read}
	\end{figure}	 	
	
    Figure \ref{fig:zookeeper_read} shows how Zookeeper services read and write requests from clients.  Stages 1-3 are the steps executed when a client write request is received, with each replica required to forward a client write request to the master node.  This process is identical to that utilised for all requests in the Chubby system, as shown in figure \ref{fig:chubby_leader_write}.  However, unlike in Chubby, client read requests can be handled by any replica node including the master.  Stages A and B, in \ref{fig:zookeeper_read} show how a Zookeeper service handles client read requests that are received by replica nodes; with a request being received by a replica node (\emph{stage A}), and a response containing the latest version of the requested data being returned to the client node (\emph{stage B}).  

	Distributing read requests across the entire Zookeeper service mitigates the bottleneck observed in the Chubby service, however the problem is not eradicated as all write requests are still served by a single master node.  This limitation results in Zookeeper services favouring workloads that have a read/write ratio of 10:1. Furthermore, when client read requests are handled by the replica nodes it is possible for stale values to be returned to the requesting client.  This occurs if a client requests a value from a replica that has missed an \emph{abcast} by the master node due to the replica not participating in an earlier quorum.  Therefore, a Zookeeper service can only be considered weakly-consistent.   
	
\clearpage
\section{In-Memory Databases}
In-memory databases\citep{Infinispan, Hazelcast, GridGain, OracleCoherence, PivotalGemFire, Schiper:2010:PGP:1915085.1916444} are database systems that aim to provide scalable, low-latency data storage.  Data is stored in RAM to provide fast data access, and is partitioned across multiple nodes in a cluster for scalability.  In order to provide availability and durability in the presence of node failures, each partition is replicated across distinct nodes; the number of replicas utilised for each data partition is the \emph{Replication Factor} ($RF$).  Storing data in RAM provides superior read/write performance to traditional disk-based databases, whilst the distributed nature of the database allows it to elastically scale by simply adding additional nodes to store data partitions.  

The emergence of simpler NoSQL based data models, such as key/value pairs, has enabled in-memory databases to become a reality.  Previously, RDBMS services were the de facto standard for database solutions, however their rigid structure greatly limits their ability to elastically scale due to the difficulty of maintaining table structures and distributing records across multiple nodes\citep{Cattell:2011:SSN:1978915.1978919, Cooper:2010:BCS:1807128.1807152}. Distributing data across many nodes is essential for in-memory databases, not only to provide availability, but to provide sufficient storage capacity for a database system; RAM per node is typically measured in gigabytes, whereas disk based storage is measured in terabytes.  

Finally, due to RAM being a volatile storage medium (i.e its state is lost when power is lost) it is common for in-memory databases to provide a means for persistent storage in the event of power-loss or node crashes.  Typically, this is achieved through asynchronous write-requests to a persistent database that utilises the same data model as the in-memory database.  However, in some deployments, such as distributed caches, this is forsaken in order to provide applications with the lowest possible response time.  
    
    \subsection{Replication Schemes}\label{replication_schemes}
	Typically, in-memory databases offer two types of replication schemes: \emph{full} and \emph{partial} replication.  
	
	\textbf{\emph{Full Replication}} is a data scheme where each data partition is replicated on every distinct node in the cluster, $RF = \left\vert nodes \right\vert$.  This greatly limits the scalability of the database, as the total number of RPCs required to update each key/value pair increases when additional nodes are added to the cluster.  Furthermore, the maximum storage capacity of the database will always be equal to the RAM size of the least capable node in the cluster.  The advantages of using \emph{full} replication is that it can provide high availability, with only a few cluster nodes, as well as providing high-performance when workloads are read dominant; full replication is extremely effective for creating a highly-available distributed cache that sits between the application and a persistent data store.  
	
	\textbf{\emph{Partial Replication}} is a data scheme where each data partition is replicated across a subset of nodes in the cluster, with no node hosting more than a single replica of a given partition and no node storing all partitions of the database \citep{Schiper:2010:PGP:1915085.1916444}.  The advantage of this partial replication, is the total size of the database is not limited by the weakest node, rather the collective memory pool of all nodes in the cluster and the $RF$ configured by the system administrator.  Therefore, elastic scalability is possible as the database's capacity can be increased by simply adding an additional node to the cluster.  Ultimately, the scalability of a partially replicated database is determined by the size of $RF$; a high $RF$ value ($RF > 3$) will provide high levels of availability and fault-tolerance at the expense of write latency (as all $RF$ replicas need to be updated); whereas too low a value will provide low-latency writes at the expense of fault-tolerance and availability.   Defining the optimum size of $RF$ and the total number of nodes required within an in-memory database is a non-trivial task which is explored in detail in \citep{DiSanzo:2013:FHP:2512734.2512743}.  
	
	The total capacity of a partially replicated database can be expressed as:
	
	\begin{equation*}
		     \begin{aligned}
		       \frac{Memory - Sys.Reserve}{RF}
		     \end{aligned}
	\end{equation*}	
	
	 Where $Memory$ is the total amount of RAM available across the cluster, $Sys.Reserve$ is the RAM required by other system resources (operating system etc.) and $RF$ is the configured \emph{replication factor}.  

%Persistence is typically provided through asynchronous write-requests, however performance can be improved further by utilising a purely in-memory solution.  tx logs, sacrifice durability in ACID because of volatile nature

\section{Infinispan}\label{sec:infinispan}
Infinispan \citep{Infinispan, marchioni2012infinispan} is an open-source in-memory database system developed by Red Hat, Inc \citep{RedHat}. that provides users with a JSR-107 \citep{JSR-107} compliant, key/value data model.  It can be used as a distributed cache, or as a transactional NoSQL key/value store, and supports both full and partial replication.  From its inception Infinispan has been designed  to be highly-scalable, this section describes how Infinispan has addressed the challenge of implementing scalable transactions, and the limitations of their current solutions.  

As previously stated ($\S$ \ref{replication_schemes}), full replication is not scalable, therefore the rest of this document will focus on the challenges posed by partial replication schemes; henceforth any reference to key/value replication assumes partial replication.  Furthermore, all references to read/write operations are assumed to be in the context of Infinispan transactions, non-transactional operations are not considered.  

    \subsection{Key Distribution}
    A key challenge of implementing distributed data stores is ensuring that each node in the cluster is aware of where each data item is located, so that any node can access data when required.  This problem is further exasperated by Infinispan's need to elastically scale.  
    
    A naive solution is for each node in the cluster to maintain meta-data about each key/value pair stored in the database, however the maintenance of such data would create a large overhead.  Not only would the database require additional space to store the meta-data, but it would also have to update the meta-data stored on each node in the cluster every time a node was added or removed from the cluster.  Clearly this is not a scalable solution.  
    
    Infinispan solves this problem, by utilising a modified consistent hashing algorithm\citep{Karger:1997:CHR:258533.258660, Infinispan, Ruivo:2011:ETO:2120967.2121604} to determine where key/value pairs should be stored; the algorithm utilises the key as a parameter for computing the hash.  The hashing algorithm divides the cluster into segments, with each hashed key mapping to a single segment, and associates $RF$ nodes with each segment. The nodes for each segment are stored in an ordered list, with the index of a node determining its replica status.  Nodes stored at index 0 are considered the \emph{primary} owner of all keys stored in that segment, and nodes with an index greater than 0 are considered \emph{backup} owners; \emph{primary} owners are used by Infinispan to coordinate various database operations; \emph{backup} owners store data purely for fault-tolerance.  
 
    Utilising this consistent hashing algorithm means it is possible for a node to determine the \emph{primary} and \emph{backup} location of any key $k$ in the cluster by calling $hash(k)$. This enables any node in the cluster to deterministically calculate the storage location of any key/value in the database without a single RPC, therefore reducing RPCs and aiding scalability.  
    
%    A consequence of utilising a consistent hash function is that Infinispan users cannot specify where data should be stored in the database. This can be advantageous when the user knows that a small set of keys will commonly be read together.  In such cases, it could be beneficial to store the keys across the same range of \emph{primary} and \emph{backup} owners in order to reduce the number of RPCs required.  Infinispan circumvents this problem by allowing users to generate keys, using a modified version of the hash function, whose owners will be the same as a specified key.  
%    
    \subsection{Transactions}
    %TODO? More info on optimistic and pessimistic transactions
    Unlike many NoSQL databases Infinispan can be used as a transactional data-store, with both the JTA\citep{JTA} and XA\citep{XA} standards supported.  Both optimistic\citep{Kung:1981:OMC:319566.319567} and pessimistic transactions\citep{Bernstein:1981:CCD:356842.356846} are provided, however optimistic transactions are used in the default Infinispan configuration in order to reduce contention and the chance of deadlock.  The traditional Two Phase Commit protocol (2PC)\citep{Bernstein:1996:PTP:261193} is utilised for implementing the locking strategy in both optimistic and pessimistic transactions.  In addition to the two traditional lock based transactions, Infinispan also offers a lock-free total order transaction scheme that relies on an atomic multicast protocol to coordinate transactions.  
	    
    The remainder of this section details the topology of Infinispan transactions, the relaxed ACID guarantees that they provide, and an in-depth explanation of how transactions are coordinated using locking (2PC) and lock-free (Total Order) schemes. 
    
		\subsubsection{Transaction Topology}
		For all transaction flavours offered by Infinispan, the following always applies.  A Transaction ($Tx$) is executed \emph{locally} by the transaction coordinator $Tx.c$, before a prepare $prepare(Tx)$ message is sent to all nodes $Tx.dst$ involved in the $Tx$.  Only $get(k)$ operations are executed locally by $Tx.c$, and this involves sending a RPC to remote nodes if $k$ is not stored locally.  Once all $get()$ operations have been satisfied locally, the values of $k$ are included in a $prepare(Tx)$ message that is sent to $Tx.dst$.  Each member of $Tx.dst$ then validates $Tx$, $validate(Tx)$, before committing $Tx$ $commit(Tx)$.  It is only during the $commit(Tx)$ operation that write operations are executed and these operations are only executed on nodes that host a key that is being inserted or updated.  For example if $k$ is stored on $N_1$ and $N_2$, the operation $update(k, v)$ will only be executed by nodes $N_1$ and $N_2$.  
		
		Note, Infinispan does offer some operations, such as \textsf{Map.put(k,v)}, that require a $get(k)$ to be executed locally by $Tx.c$ and a write operation by the nodes hosting $k$, however for the sake of brevity it is assumed that all operations are exclusively read or write.  Furthermore, write operations are often executed on nodes other than the host of a key being updated so that they can be stored in a local cache in order to reduce the total number of RPCs, however this optimisation is not core to the Infinispan protocol and can be disabled, therefore this functionality is also omitted for the sake of brevity.  
    
	    \subsubsection{Relaxed ACID}
	    Infinispan transactions abide by the ACID\citep{Haerder:1983:PTD:289.291} properties, however the \emph{Isolation} and \emph{Durability} guarantees are more relaxed than those provided by traditional RDBMS transactions; Durability is relaxed as a consequence of RAM being volatile, and Isolation level is relaxed from the traditional $1$-copy serialisability in order to reduce the overhead of maintaining distributed transactions in a \emph{partially replicated} context.  
	    
		    \subsubsection*{Durability}
		    Infinispan provides two mechanisms for providing durability: the first is the use of redundant key backups, i.e. the \emph{replication factor}, and the second is an optional mechanism that allows key/value pairs to be persisted to a separate persistent database.  The latter is available in two different configurations, \emph{write-through} and \emph{write-beyond}. 
		    
		    Write-through is a synchronous operation, that ensures that an insert/update operation on an Infinispan key will not complete until the value has been updated in the cache and it has been updated at the persistent store.  This ensures that the contents of the cache will always be consistent with the persistent store, therefore guaranteeing that in the event of a system wide crash all committed key/value pairs will be preserved.  The disadvantage of this approach is that the users of the cache lose the performance benefits provided by in-memory storage as any update/insert operation will always take at as long as storing the pair in a persistent store.  Ultimately, write-through is only an appropriate solution in read-heavy workloads that require a strong emphasis on durability.  
		    
		    Conversely, write-beyond offers asynchronous persistence.  Key/value updates and inserts complete as soon as the operation has completed in the cache, and the values are persisted in the background using a separate thread to the users request.  This ensures that the users operation is returned as quick as possible, and low-latency is maintained, however it presents a small window in which the cache is not consistent with the persistent data store.  Therefore, it is possible for the most recent key/value write operations to be lost if all nodes containing $RF$ backups simultaneously crash or the entire cluster goes down.  
    
	        \subsubsection*{Isolation}\label{ssec:infi_isolation}
	        Infinispan does not provide support for 1-copy serialisability in its transactions, instead it provides two different isolation criteria: \emph{Read Committed (RC)} and \emph{Repeatable Read (RR)}.  
	        
	        \begin{itemize}
	            \item[\textbf{RC} -] All calls to a key $get(k)$ return the last value of $k$ committed by a transaction.  
	            \item[\textbf{RR} -] The value returned by the first call to $get(k)$ will be used for all subsequent calls to $get(k)$ within a transaction.
	        \end{itemize}   
	        
	        RC is advantageous as it ensures that all calls to $get(k)$ always return the the last committed value of $k$ at the time of the $get(k)$ operation, however each call to $get(k)$ may require a RPC as $k$ may not be stored on the local node due to $k$ only being partially replicated across the cluster. Thus, RC can be detrimental to performance in transactions that consist of multiple reads to the same key.  If such transactions are prevalent in a workload, it may be advantageous to utilise RR isolation in order to reduce the total number of RPCs required by a transaction.  
	        
	        Infinispan implements RR by storing the value returned by $get(k)$ in the transaction manager's context, and simply returns the stored value for any subsequent calls to $get(k)$ within this transaction.  A consequence of adopting RR is that the potential for stale values to be utilised by a transaction, $Tx_j$, increases.  This occurs if another transaction, $Tx_i$, commits before $Tx_j$ and updates $k$, as $Tx_j$ will still be utilising the previously committed value of $k$.  If $Tx_j$ attempts to perform a write operation utilising this stale value of $k$, then the values committed in $Tx_i$ will be ignored; this is referred to as a \emph{write-skew}.  To detect when \emph{write-skews} occur, Infinispan provides an optional \emph{Write Skew Check (WSC)} that enables transactions to be aborted when such anomalies are detected\footnote{WSC is only available when Repeatable Read isolation is utilised, as \emph{write-skews} are not possible with Read Committed isolation.}.  
	        
	        The WSC determines whether a read operation, $v = get(k)$, in a transaction $Tx_j$, has been invalidated by a concurrent transaction $Tx_i$ committing a $update(k, v')$ operation during the lifetime of $Tx_j$.  If $Tx_i$ has committed a write operation on $k$ between $Tx_j$ performing $get(k)$ and $update(k, v+1)$, then the WSC will detect this and allow the transaction manager to abort $Tx$ so that the erroneous value $v+1$ is not committed.  

        
	    \subsubsection{Two-phase Commit Protocol}\label{ssec:2PC}
	       The Two-phase commit protocol (2PC)\citep{Bernstein:1996:PTP:261193} is the traditional approach to coordinating distributed transactions, and as such its benefits and limitations are well understood.  Infinispan utilises the 2PC protocol for coordinating both optimistic and pessimistic transactions.  
	       
           \subsubsection*{Example Scenario} \label{transaction_scenario} 
           Consider the following scenario: a node $N_1$ executes a transaction $Tx$ that consists of a single write operation $update(k, v)$, however the primary and backup of $k$ are stored on $N_2$ and $N_3$ respectively, therefore it is necessary for $Tx$ to be committed at $N_1, N_2$ and $N_3$ ($Tx.dst = N_1, N_2, N_3$).  To ensure that all three nodes come to the same conclusion about the transaction, whether to commit or abort, the 2PC protocol is used.  
	       
	       \subsubsection*{Protocol Details}
	       The 2PC is leader-based consensus algorithm that is specifically designed for coordinating distributed transactions, as the name suggests the protocol consists of two distinct phases: \emph{voting} and \emph{commit}. 
	       
	       \textbf{\emph{Voting Phase.}} The transaction coordinator $Tx.c$, ($Tx.c = N_1$) sends a prepare, $prepare(Tx)$, message to all $Tx.dst$.  Upon receiving the $prepare(Tx)$ message, all members of $Tx.dst$ will validate, $validate(Tx)$, the transaction and decide whether the $Tx$ should be committed or aborted.  Once a decision has been made by a node, it sends its vote, $vote(Tx)$, to $Tx.c$, and awaits further instructions.  
	       
	       \textbf{\emph{Commit Phase.}}  Once the $Tx.c$ has sent $prepare(Tx)$ to all $Tx.dst$, and has validated $Tx$, it waits to receive a $vote(Tx)$ from all $Tx.dst$.  If all $Tx.dst$ respond with a commit verdict, then $Tx.c$ sends a final commit message, $commit(Tx)$, to all $Tx.dst$, and commits $Tx$ locally.  However, if $Tx.c$ receives a single vote in favour of aborting $Tx$, then $Tx$ must be aborted, so $Tx.c$ sends a abort message $abort(Tx)$ to all $Tx.dst$; $Tx.c$ does not need to wait for all $vote(Tx)$ before issuing $abort(Tx)$, instead $abort(Tx)$ is issued as soon as the first abort vote has been received.  Finally, upon receiving a $commit(Tx)$ or $abort(Tx)$ each member of $Tx.dst$ will abort or commit $Tx$ locally.  
	       
	       Figure \ref{fig:2PC} shows all of the sequences involved in 2PC based upon the example scenario, and assumes that all $Tx.dst$ vote in favour of committing $Tx$.  
	       	       
            \begin{figure}[htbp!] 
                \centering    
                \includegraphics[width=1.0\textwidth]{2PC}
                \caption[Two-phase Commit Protocol]{2PC Sequence Diagram}
                \label{fig:2PC}
            \end{figure}
            
	        \subsubsection*{Key Locking}
	        As previously stated, Infinispan has the notation of \emph{primary} and \emph{backup} owners of key/value pairs.  This is utilised by many functions within Infinispan, but one of the most important uses is for determining which data replica should be locked during write transactions.  Infinispan always locks the \emph{primary} owner of $k$ for write operations, never a \emph{backup}, therefore allowing each transaction to acquire a lock on $k$ at a single node.  Thus limiting the number of RPCs required to one, instead of $RF$ RPCs. For example in the previous scenario, if the \emph{primary} owner of $k$ was $N_2$ and the backup $N_3$, then the write lock for $k$ would only be acquired at $N_2$.  
	        
	        The time at which $k$'s lock is acquired is a defining characteristic of how transactions are handled.  Infinispan provides two different approaches, the more cautious Pessimistic transactions which utilises pessimistic locking, and Optimistic transactions that utilises optimistic locking.  Each approach is detailed below along with the benefits and limitations of each approach.  
	         
            \textbf{Pessimistic Locking.}
            When pessimistic locking\citep{Bernstein:1981:CCD:356842.356846} is used, the lock on $k$ is acquired the first time that a write operation is performed on $k$ in $Tx$ and it is held until $Tx$ either commits or aborts.  
	       		    
		    \begin{lstlisting}
		    	Tx.begin();
		    	update(k,v); // Lock is acquired
		    	Tx.commit(); // Lock is released
		    \end{lstlisting}

            This means that a RPC is issued for every write operation in the transaction, at the time the operation is encountered.  Not only does this result in an increase in network traffic, due to the number of RPCs required being equal to the number of write operations, but it also means that locks are held for a longer period of time, increasing the likelihood of deadlocks occurring \footnote{Details of which can be found in the next section "2PC Limitations".}.
            
	        \textbf{Optimistic Locking.}
	        When optimistic locking\citep{Kung:1981:OMC:319566.319567} is used, the lock on $k$ is only acquired during the $prepare(Tx)$ phase of the transaction.  This means that no additional RPCs are required for locking, instead the lock is acquired by $k$'s primary owner when it receives $prepare(Tx)$ from $Tx.c$ and $Tx$ is processed locally.  The lock is then released by $k$'s primary owner when $Tx$ commits or aborts.  
	        
	        Acquiring locks during the prepare phase of a transaction means that is possible for a  \emph{write-skew} ($\S$ \ref{ssec:infi_isolation}) to occur, therefore an optimistic transaction can be aborted due to failing the WSC (if enabled).  However, acquiring locks during the prepare phase also reduces the total number of RPCs required by a transaction, which can improve scalability and throughput.  
	        
	        Optimistic locking is the default locking strategy employed by Infinispan, henceforth all references to lock-based transactions in Infinispan assume optimistic locking.  
	        
	        \subsubsection*{2PC Limitations}
	        The key limitation of utilising the 2PC protocol with locking (both optimistic and pessimistic) is that it is susceptible to deadlocks.  Deadlocks occur when two concurrent transactions are trying to acquire a lock on the same set of keys.  Consider a situation where $Tx$ and $Tx'$ are executing concurrently, and both transactions want to write to key $k_1$ and $k_2$.  It is possible for $Tx$ to acquire a lock on $k_1$ with $update(k_1)$, and $Tx'$ to acquire $k_2$'s lock with $update(k_2)$.  In this scenario, it is impossible for either $Tx$ or $Tx'$ to progress as both are waiting to acquire the locks held by each other, hence deadlock.  
	        
	        Infinispan utilises timeouts in order to recover from deadlocks, with a default timeout of 10 seconds.  The transaction coordinator will wait a maximum of 10 seconds for $k$'s lock to become available, if $k$'s lock does not become available during this period, then the transaction coordinator aborts the transaction.  The limitations of this approach are that it is possible for \emph{false suspicions} to occur, as transactions can timeout due to other circumstances, such as high network load.  Furthermore, in workloads where high levels of contention are present, deadlock becomes increasingly likely, resulting in more transactions aborting, which ultimately leads to a drop in transaction throughput and Infinispan's request latency increasing.  

	    \subsubsection{Total Order Commit Protocol} \label{sec:to_commit}
	    In addition to the 2PC locking approach, Infinispan also provides a lock-free total order commit protocol, that provides the same guarantees as 2PC (\emph{Read Committed}, or \emph{Repeatable Read}) without locking key/values during write operations.  
	    
	    The key benefit of a total order commit, is that it does not utilise locks to ensure ACIDity.  Instead it utilises the guarantees (G1-G4 $\S$ \ref{sec:atomic_guarantees}) provided by \emph{abcast} and \emph{amcast} protocols to ensure that transactions are processed sequentially and in the same total order at all destinations.  The absence of locks removes the potential for distributed deadlocks, which reduces the total number of aborting transactions, therefore an increase in transaction throughput is expected.  
	    
	    Ruivo \emph{et al.}\citep{Ruivo:2011:ETO:2120967.2121604} conducted a thorough performance evaluation of the Total Order Commit protocol, utilising Red Hat's bespoke benchmark, RadarGun\citep{RadarGun}, and the industry standard benchmark, TPC-C\citep{TPC-C}.  For each benchmark they found that when RC or RR consistency guarantees ($\S$ \ref{ssec:infi_isolation}) were utilised, the transaction abort rate was reduced dramatically when key/value pairs were exposed to both high and low levels of contention.  As expected this resulted in an increased throughput rate and a reduction on the average latency encountered per transaction.  The difference between abort rates when comparing 2PC locking and Total Order Commit, was much smaller when the benchmarks were performed using RR consistency with the WSC enabled.  This is because when the WSC check is enabled it is possible for transactions to abort if a key/value pair has become invalidated by another concurrent transaction.  However, despite the difference in abort rates being reduced, the Total Order Commit protocol still provides a marked improvement in transaction throughput and latency over the 2PC approach.  
	    
	    In addition to eliminating deadlocks,  the use of total order commit allows transactions to be committed in only one phase (1PC) when RC or RC is used.  The workings of 1PC and how the WSC is executed in Total Order commits are explored below.  
	    
	        \subsubsection*{One-Phase Commit}
	        Consider the scenario in \ref{transaction_scenario}.  The transaction coordinator $Tx.c$, ($Tx.c = N_1$), executes the transaction locally (i.e. all $get(k)$ operations are resolved) and sends $prepare(Tx)$ using an atomic multicast protocol to $Tx.dst$.  Because $prepare(Tx)$ is sent to $Tx.dst$ using an \emph{amcast} protocol, we can guarantee that all $Tx.dst$ will receive $prepare(Tx)$ in the same total order.  Therefore if RR or RC is used, each transaction can be committed as soon as it is received by a node without violating Infinispan's ACID properties.  Figure \ref{fig:total_order_1PC} , below, shows the sequences involved in a 1PC transaction.  
	        
            \begin{figure}[htbp!] 
                \centering    
                \includegraphics[width=1.0\textwidth]{1PC-Amcast}
                \caption[Total Order One-phase Commit Protocol]{Total Order 1PC Sequence Diagram}
                \label{fig:total_order_1PC}
            \end{figure}	        
	        
		        
			\subsubsection*{Two-Phase with WSC}      
	        If RR is utilised with WSC enabled, the total order commit becomes a two-phase protocol.  The first phase is the same as above, with $Tx.c$ sending $prepare(Tx)$ to all $Tx.dst$ using an \emph{amcast} protocol, however it is not possible to commit the transaction instantly, instead an additional voting stage is required.  All $Tx.dst$ validate the transaction based upon the WSC criteria and decide whether the transaction should be committed or aborted, this vote $vote(Tx)$ is then sent to $Tx.c$.  The $Tx.c$ waits to receive a $vote(Tx)$ from all $Tx.dst$, before sending a $commit(Tx)$ or $abort(Tx)$ to all $Tx.dst$.  Finally, upon receiving a $commit(Tx)$ or $abort(Tx)$ each member of $Tx.dst$ will abort or commit $Tx$ locally.          
	        
			The overhead of this additional phase is slightly reduced by two minor optimisations.  First, the $Tx.c$ does not have to receive a vote from all nodes hosting a key replica, just one, as the processing of a transaction is deterministic it is guaranteed that all replicas reach the same conclusion during WSC validation.  Secondly, like 2PC, as soon as a single $abort(Tx)$ vote is received by $Tx.c$ the transaction is aborted.  
			
			Figure \ref{fig:total_order_wsc} shows the sequences involved in a transaction that utilises the WSC.  In this figure we have assumed that $Tx.c$ receives $vote(Tx)$ from both $N_2$ and $N_3$ before sending $commit(Tx)$, however, as stated above, this is not essential, and it is valid for $Tx.c$ to have only received $vote(Tx)$ from $N_2$ or $N_3$ before sending $commit(Tx)$.  
	        
	        \begin{figure}[htbp!] 
                \centering    
                \includegraphics[width=1.0\textwidth]{WSC-Amcast}
                \caption[Total Order Commit with Write Skew Check]{Total Order Commit with WSC Sequence Diagram}
                \label{fig:total_order_wsc}
            \end{figure}	      	                         
             
	        \subsubsection{Total Order Anycast - Atomic Multicast Protocol} \label{ssec:TOA_limations}
	        Total Order Anycast (TOA)\cite{Ruivo:2011:ETO:2120967.2121604} is the \emph{amcast} protocol currently utilised by Infinispan for coordinating Total Order transactions (\ref{sec:to_commit}).  It is a GM dependent protocol that, like Newtop\citep{Ezhilchelvan:1995:NFG:876885.880005}, utilises logical clocks and acknowledgements, to solve C1 and C2 (\ref{sec:atomic_guarantees}) respectively.  
	        
			TOA's structure is very similar to the 2PC protocol, in that it consists of two distinct phases, both of which are required for a message $m$ to be delivered.  The \emph{ack phase} requires that all destinations in $m.dst$ acknowledge the message origin $m.o$, and the \emph{delivery phase} involves $m.o$ instructing all $m.dst$ to deliver $m$.  Thus the ack and delivery phases are the equivalent of the \emph{vote} and \emph{commit} phases, respectively.  
	        
			The ack phase consists of all $d' \in m.dst-\{m.o\}$ acknowledging $m$ by sending $ack_{d'}(m)$ to $m.o$.  Once $m.o$ has received all $ack_{d'}(m)$, the ack phase is complete, and C1 is guaranteed as all $m.dst$ are known to have received $m$.  
			
			The delivery phase in TOA is necessary to ensure that all $m.dst$ know the final total order of $m$. Like the Newtop protocol, TOA ensures C2 by piggybacking the timestamp of a sending node's logical clock onto all $m$, $ack(m)$ and $deliver(m)$ messages sent from that node.  However, in TOA the final timestamp of $m$ is always finalised by $m.o$ after the ack phase has completed, with the $deliver(m)$ message dictating the final timestamp of $m$ to all $m.dst$ in order to dictate $m$'s place in the total order.  Figure \ref{fig:TOA} shows the communication stages required for \emph{amcast}ing $m$ between nodes $N_1, N_2 and N_3$.  
			
            \begin{figure}[htbp!] 
                \centering    
                \includegraphics[width=1.0\textwidth]{TOA}
                \caption[Total Order Anycast Protocol]{Total Order Anycast Sequence Diagram}
                \label{fig:TOA}
            \end{figure}	 			
			
			The advantage of utilising $m.o$ as a central coordinator, opposed to all $m.dst$ acknowledging each other, see Figure \ref{fig:newtop}, is that the total number of messages involved in a single \emph{amcast} is reduced as $\left\vert m.dst \right\vert$ increases.  The total remote message cost for TOA and Newtop is expressed below:
            
%            Note that $x (x + 1) > 3x \quad \forall x > 2$, i.e. when $|m.dst| > 3$.  
			
			\begin{samepage}
                Let $x = |m.dst| -1$.  In TOA, $m.o$ transmits $2x$ messages and the other nodes in $m.dst$ transmit $1$ ack each.  So TOA's message cost is $3x$.  Whereas, in Newtop, each node in $m.dst$ sends $x$ messages each, hence the cost is $x(x+1)$.  Note that:
				\begin{equation*}
				x (x + 1) > 3x \quad \forall \quad x > 2
			    \end{equation*}
			    
			     \emph{i.e.} when $|m.dst| > 3$.
            \end{samepage}
            
	        \subsubsection*{TOA Limitations}
			The TOA protocol suffers from the same limitations as other GM based protocols, such as NewTop, most notably that message delivery is blocked in the presence of node failures.  In the context of Infinispan total order transactions, a crashed node $c$ will cause all transactions that interact with $c$ to block until the GM service issues a new view.  This causes the \emph{liveness} of all nodes interacting with $c$ to be lost in the interim period, as the blocked transactions will not be able to commit, resulting in a loss of throughput.  
	        
	        Another limitation of the TOA protocol is that it does not scale well as the number of destinations $N$ increase.  All multicast protocols incur $1->N$ communication (i.e. $m.o$ multicasting $m$ to all $m.dst$) as it is necessary for each destination to receive $m$.  However, $N->1$ communication (i.e. $N$ destinations in $m.dst$ sending an acknowledgment to $m.o$) is expensive, as the total time taken is equal to the slowest $N$.  Therefore, any protocol that relies on $N->1$ communication is more liable to encounter slow or crashed nodes as $N$ increases, and is ultimately more likely to block.  This means that as the number of operations in a transaction increases and keys become more distributed, the latency involved in each transaction will also increase, severely hampering Infinispan's ability to scale elastically.  
	        

\section{JGroups}
JGroups \citep{JGroups} is a network framework written in the Java programming language, which provides implementations of many network protocols that can be utilised on their own, or as part of a network stack.  Furthermore, the framework provides an abstraction that allows users to write their own network protocols that can be utilised within the network stack alongside existing JGroups protocols.  Infinispan utilises the JGroups framework for all distributed communication and consequently all of the network protocols presented in this thesis have also been implemented using the JGroups framework.  

As previously stated, the JGroups framework provides implementations of various network protocols.  Of particular interest to this project are TOA and GMS, as they are both utilised by Infinispan for atomic multicast and group membership services, respectively.  The TOA protocol has already been discussed in detail in section \ref{sec:infinispan}, therefore the remainder of this section details the inner working of GMS and the protocols from which it depends.  It is necessary to detail these protocols in order to show that, with a very high probability, node crashes will be detected within a matter of seconds by the GMS protocol.  Furthermore, the inner workings of these protocols are essential for understanding the design decisions made in chapter \ref{ch:abcast} and the experiments conducted in chapter \ref{ch:perf_eval}.  

\subsection*{Group Membership Service} \label{ssec:jgroups_gms}
The GMS protocol keeps track of the current members of the network group by issuing network views, with each view containing the address of each respective member.  Upon a node joining or leaving the network, a new view is issued to all nodes whose address appears in the updated view of the network.  The purpose of the GMS protocol is to update the current view of the network when changes occur, however it does not detect these changes itself, instead it relies on lower level protocols in the JGroups stack.  Discovering new nodes is trivial, therefore the inner workings of these operations are not detailed further.  However, the detection of node failures is non-trivial, due to the FLP impossibility stated earlier, and as such the GMS protocol relies on three additional protocols to detect node crashes.  These three \emph{failure detection} protocols are called \emph{\texttt{FD\_SOCK}}, \emph{\texttt{FD\_ALL}} and \emph{\texttt{VERIFY\_SUSPECT}}; all of which pass a \texttt{SUSPECT} message up the stack when a node is suspected of crashing.  The remainder of this section details the workings of each protocol as well as providing a short conclusion that states how effective these protocols are at correctly identifying a node as crashed.  
    
    \subsubsection*{FD\_SOCK}     
    \texttt{FD\_SOCK} is the lowest of the three protocols in the stack, and it utilises a \textquoteleft{}ring' of TCP sockets, which is established between each node in the current view, to detect if one or more nodes become inoperative \footnote{All of the experiments detailed in this thesis utilise UDP packets for sending unicasts, however the TCP sockets are still open as part of the \texttt{FD\_SOCK} protocol and are present purely for failure detection.}.  If a node's TCP socket is abruptly closed, then \texttt{FD\_SOCK} suspects that the node has crashed and issues a \texttt{SUSPECT} message.  Conversely, if a node wishes to leave the view gracefully, i.e it has not crashed, then a leaving message is sent around the ring of TCP sockets before the node closes its socket.  This leaving message is sent when the JGroups shutdown hook is activated during the normal shutdown process of a Java program (calling System.exit() or requesting the process is terminated at the OS level).  
    
    \subsubsection*{FD\_ALL} 
    \texttt{FD\_ALL} is a failure detector protocol that utilises a simple heartbeat protocol \citep{AW98} to issue \texttt{SUSPECT} messages.  Each node periodically sends a heartbeat message to all other nodes in the current view, and suspects another member of crashing if a heartbeat message has not been received after a specified timeout.  By default, \texttt{FD\_ALL} utilises a timeout value equal to $40$ seconds with each heartbeat message sent every $8$ seconds.  
    
     \subsubsection*{VERIFY\_SUSPECT} 
    Finally, the highest failure detection protocol in the stack, is the \texttt{VERIFY\_SUSPECT} protocol.  This protocol aims to reduce the chances of a node being falsely suspected of crashing by intercepting \texttt{SUSPECT} messages, sent from lower in the stack, and attempting to contact the suspected node for a final time.  If no response is received within $1.5$ seconds, then the \texttt{SUSPECT} message is sent upto the GMS protocol and the node will be excluded from the current view.  Otherwise, the original \texttt{SUSPECT} message is discarded as we know that the suspected node must be alive if it is able to respond to this protocol.  
    
     \subsubsection*{Summary} 
    When utilised simultaneously the three protocols described above provide an effective method for detecting node crashes, with initial experiments showing that the \texttt{FD\_SOCK} protocol was particular effective at detecting crashed nodes due to it not relying on large timeout values.  Furthermore, due to the combination of TCP sockets, the large timeout of \texttt{FD\_ALL} and the additional waiting period of \texttt{VERIFY\_SUSPECT}, the probability of a node being falsely suspected of crashing is very small.  